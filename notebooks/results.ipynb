{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faef2e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from matplotlib.font_manager import findSystemFonts\n",
    "from scipy.io import loadmat\n",
    "\n",
    "def iterate_group(data: h5py.Group, final_data: dict):\n",
    "    \"\"\"\n",
    "    Recursively iterate through a h5py Group and print its structure.\n",
    "    \"\"\"\n",
    "    for key in data.keys():\n",
    "        item = data[key]\n",
    "        if isinstance(item, h5py.Group):\n",
    "            final_data[key] = {}\n",
    "            iterate_group(item, final_data[key])\n",
    "        else:\n",
    "            final_data[key] = item[:]\n",
    "    return final_data\n",
    "\n",
    "def load_data_matfile(path: str, name: list[str]=[]):\n",
    "    with h5py.File(path, 'r') as f:\n",
    "        # List all groups in the file\n",
    "        # print(\"Keys in the file:\", list(f.keys()))\n",
    "        # Access the dataset\n",
    "        \n",
    "        if len(name) == 0:\n",
    "            data = {}\n",
    "            iterate_group(f, data)\n",
    "            return data\n",
    "        else:\n",
    "            result = {}\n",
    "            for key in name:\n",
    "                if isinstance(f[key], h5py.Group):\n",
    "                    # print(\"key is a group, iterating through it\")\n",
    "                    result[key] = iterate_group(f[key], {})\n",
    "                else:\n",
    "                    # print(\"key is a dataset, returning data\")\n",
    "                    data = f[key][:]\n",
    "                    data = data.T  # Transpose to match MATLAB's column-major order\n",
    "                    result[key] = data \n",
    "            return result\n",
    "\n",
    "def load_result_matfile(path: str):\n",
    "    data = loadmat(path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3660794e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  FBIRN\n",
      "Round 0: \n",
      "total typical subjects:  191\n",
      "total typical SZ subjects:  99\n",
      "total typical HC subjects:  92\n",
      "Round 1: \n",
      "total typical subjects:  191\n",
      "total typical SZ subjects:  99\n",
      "total typical HC subjects:  92\n",
      "SZ: Typical Subjects present in all the rounds:  99\n",
      "SZ: Inconsistent:  0\n",
      "HC: Typical Subjects present in all the rounds:  92\n",
      "HC: Inconsistent:  0\n",
      "\n",
      "Dataset:  COBRE\n",
      "Round 0: \n",
      "total typical subjects:  103\n",
      "total typical SZ subjects:  55\n",
      "total typical HC subjects:  48\n",
      "Round 1: \n",
      "total typical subjects:  103\n",
      "total typical SZ subjects:  55\n",
      "total typical HC subjects:  48\n",
      "SZ: Typical Subjects present in all the rounds:  55\n",
      "SZ: Inconsistent:  0\n",
      "HC: Typical Subjects present in all the rounds:  48\n",
      "HC: Inconsistent:  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def handle_count_dataset(name: str, data: h5py.Dataset):\n",
    "    print(f\"====== Count: {name} =====\")\n",
    "    \n",
    "    # Shape of the opbject and type of it : (311, 4) and ndarray\n",
    "    \"\"\"\n",
    "        1st column: subject Ids\n",
    "        2nd total no.of times it sampled\n",
    "        3rd total no.of times it is non-noised\n",
    "        4th % of non-noise labelled\n",
    "    \"\"\"\n",
    "    print(f\"Total Subjects: {data.shape[0]}\")\n",
    "\n",
    "def get_stats(site: str):\n",
    "    print('Dataset: ', site)\n",
    "    \n",
    "    PATH=\"/data/users4/rgirijala1/msproject/result/round_{number}\"\n",
    "    \n",
    "    typical_sz = {} \n",
    "    typical_hc = {}\n",
    "    rounds=2\n",
    "    for i in range(rounds):\n",
    "        path = PATH.format(number=i)\n",
    "\n",
    "        count_path = os.path.join(path, f'{site}_Count.mat')\n",
    "        typ_path = os.path.join(path, f'{site}_Typ.mat')\n",
    "        score_path = os.path.join(path, f'{site}_Score.mat')\n",
    "\n",
    "        count_mat = load_result_matfile(count_path)['count'][:]\n",
    "        score_mat = load_result_matfile(score_path)\n",
    "        typ_mat = load_result_matfile(typ_path)\n",
    "        \n",
    "        typ_sz = typ_mat['TypIDG1'].T[0]\n",
    "        typ_hc = typ_mat['TypIDG2'].T[0]\n",
    "        \n",
    "        print(f\"Round {i}: \")\n",
    "        print(\"total typical subjects: \", len(typ_sz)+len(typ_hc))\n",
    "        print(\"total typical SZ subjects: \", len(typ_sz))\n",
    "        print(\"total typical HC subjects: \", len(typ_hc))\n",
    "        \n",
    "        for i in typ_hc:\n",
    "            id = int(i)\n",
    "            if id in typical_hc:\n",
    "                typical_hc[id]+=1\n",
    "            else:\n",
    "                typical_hc[id]=1\n",
    "\n",
    "        for i in typ_sz:\n",
    "            id=int(i)\n",
    "            if id in typical_sz:\n",
    "                typical_sz[id]+=1\n",
    "            else:\n",
    "                typical_sz[id]=1\n",
    "\n",
    "    print(\"SZ: Typical Subjects present in all the rounds: \", len([key for key, value in typical_sz.items() if value == rounds]))\n",
    "    print(\"SZ: Inconsistent: \", len([key for key, value in typical_sz.items() if value != rounds]))\n",
    "    \n",
    "    print(\"HC: Typical Subjects present in all the rounds: \", len([key for key, value in typical_hc.items() if value == rounds]))\n",
    "    print(\"HC: Inconsistent: \", len([key for key, value in typical_hc.items() if value != rounds]))\n",
    "\n",
    "\n",
    "names=['FBIRN', 'COBRE']\n",
    "\n",
    "for site in names:\n",
    "    get_stats(site)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fab73bf8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'data/FBIRN.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m DataName \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFBIRN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOBRE\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m DataName:\n\u001b[0;32m----> 7\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[43mload_data_matfile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.mat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     data \u001b[38;5;241m=\u001b[39m content[i]\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape of the dataset: \u001b[39m\u001b[38;5;124m'\u001b[39m, i) \u001b[38;5;66;03m# no.of subjects with features columns\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 19\u001b[0m, in \u001b[0;36mload_data_matfile\u001b[0;34m(path, name)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_data_matfile\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, name: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]\u001b[38;5;241m=\u001b[39m[]):\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;66;03m# List all groups in the file\u001b[39;00m\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;66;03m# print(\"Keys in the file:\", list(f.keys()))\u001b[39;00m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;66;03m# Access the dataset\u001b[39;00m\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(name) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     25\u001b[0m             data \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/data/users4/rgirijala1/msproject/.venv/lib/python3.10/site-packages/h5py/_hl/files.py:564\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    555\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    556\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    557\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    558\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    559\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    560\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    561\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    562\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    563\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 564\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m/data/users4/rgirijala1/msproject/.venv/lib/python3.10/site-packages/h5py/_hl/files.py:238\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    237\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 238\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    240\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:56\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:57\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'data/FBIRN.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "DataName = ['FBIRN', 'COBRE']\n",
    "\n",
    "for i in DataName:\n",
    "    content = load_data_matfile(f'data/{i}.mat', [i])\n",
    "    data = content[i]\n",
    "    \n",
    "    print('Shape of the dataset: ', i) # no.of subjects with features columns\n",
    "    print(data.shape)\n",
    "    \n",
    "    print('last column have the labels for each subject') # 1-SZ , 2-HC\n",
    "    last_column = data[:,-1]\n",
    "    print(last_column[:10])\n",
    "    \n",
    "    total_subjects = data.shape[0]\n",
    "    sz_count = np.count_nonzero(last_column == 1)\n",
    "    hc_count = total_subjects - sz_count\n",
    "    print('count of SZ: ', sz_count)\n",
    "    print('count of Hc: ', hc_count)\n",
    "    \n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd5a2d7",
   "metadata": {},
   "source": [
    "### non-noise rate from CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69ccc5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Count: COBRE =====\n",
      "Shape: (157, 4) and type of result: <class 'numpy.ndarray'>\n",
      "first 5 rows of the count matrix\n",
      "[[ 1.         81.         80.          0.98765432]\n",
      " [ 2.         86.         86.          1.        ]\n",
      " [ 3.         76.         75.          0.98684211]\n",
      " [ 4.         54.         54.          1.        ]\n",
      " [ 5.         62.         62.          1.        ]]\n",
      "\n",
      "====== NLCTLabels: COBRE =====\n",
      "Shape: (1, 101) and type of result: <class 'numpy.ndarray'>\n",
      "Each Column data shape:  (101,)\n",
      "first iteration, first 5 subjects label decision by 5 trees\n",
      "[array([[1, 0, 1, ..., 1, 0, 0],\n",
      "        [0, 1, 0, ..., 1, 1, 0],\n",
      "        [0, 1, 1, ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 0, 0, ..., 1, 0, 0],\n",
      "        [0, 1, 1, ..., 0, 1, 1],\n",
      "        [1, 1, 1, ..., 0, 0, 1]], shape=(108, 402), dtype=uint8)\n",
      " array([[0, 1, 1, ..., 0, 0, 1],\n",
      "        [0, 0, 0, ..., 0, 1, 1],\n",
      "        [1, 1, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 1, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 1, ..., 0, 0, 0]], shape=(108, 402), dtype=uint8)\n",
      " array([[0, 0, 0, ..., 1, 0, 0],\n",
      "        [0, 0, 0, ..., 1, 0, 1],\n",
      "        [1, 0, 0, ..., 0, 1, 1],\n",
      "        ...,\n",
      "        [1, 0, 1, ..., 0, 0, 0],\n",
      "        [0, 0, 1, ..., 0, 0, 0],\n",
      "        [0, 0, 1, ..., 0, 0, 0]], shape=(108, 402), dtype=uint8)\n",
      " array([[1, 1, 0, ..., 0, 0, 1],\n",
      "        [0, 1, 0, ..., 1, 0, 0],\n",
      "        [0, 1, 1, ..., 1, 1, 0],\n",
      "        ...,\n",
      "        [1, 1, 1, ..., 0, 0, 1],\n",
      "        [0, 0, 1, ..., 0, 0, 0],\n",
      "        [0, 0, 1, ..., 1, 0, 1]], shape=(108, 402), dtype=uint8)\n",
      " array([[1, 0, 0, ..., 0, 1, 1],\n",
      "        [0, 1, 0, ..., 0, 0, 1],\n",
      "        [0, 1, 1, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1, ..., 0, 0, 0],\n",
      "        [1, 1, 1, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 1, 0]], shape=(108, 402), dtype=uint8)]\n",
      "\n",
      "====== NonNoise Ids/row numbers of Dataset: COBRE =====\n",
      "(1, 101) <class 'numpy.ndarray'>\n",
      "first iteration subject ID's resulting non-noise\n",
      "[[  1 112 101  56 152  59  31  53  18  76  81  34 150   6 107 145  98  28\n",
      "  155  11 108  68 139 100  83 113 110  78  57  27  65  40  77   2  60   3\n",
      "    9 116  62  29 141 117 102  74  43 111  22  41  47  39 104  90  63   5\n",
      "   99  71  50  12 143  67  92 151   4 129  26  36  88  61 122   8  85  96\n",
      "    7  84 133 103  35  15 130 147]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "def handle_count_dataset(name: str, data: h5py.Dataset):\n",
    "    print(f\"====== Count: {name} =====\")\n",
    "    \n",
    "    # Shape of the opbject and type of it : (311, 4) and ndarray\n",
    "    \"\"\"\n",
    "        1st column: subject Ids\n",
    "        2nd total no.of times it sampled\n",
    "        3rd total no.of times it is non-noised\n",
    "        4th % of non-noise labelled\n",
    "    \"\"\"\n",
    "    print(f\"Shape: {data.shape} and type of result: {type(data)}\")\n",
    "    \n",
    "    print(\"first 5 rows of the count matrix\")\n",
    "    print(data[:5])\n",
    "    \n",
    "def handle_nlctlabels_dataset(name: str, data: h5py.Dataset):\n",
    "    print(f\"====== NLCTLabels: {name} =====\")\n",
    "    \n",
    "    # Shape and type: 1 row and 101 columns ( total no.of iterations) , ndarray\n",
    "    print(f\"Shape: {data.shape} and type of result: {type(data)}\")\n",
    "    \n",
    "    # each column is again a sampled no of rows x 2*ntrees columns\n",
    "    print(\"Each Column data shape: \", data[0].shape) # (216, 402)\n",
    "    \n",
    "    # print 5 tree output for 5 sampled subjects in 1st iteration.\n",
    "    # gives each tree decision label, 1->noise, 0 - non-noise\n",
    "    print(\"first iteration, first 5 subjects label decision by 5 trees\")\n",
    "    print(data[0][:][:5])\n",
    "\n",
    "def handle_nonNoise_dataset(name: str, data: h5py.Dataset):\n",
    "    print(f\"====== NonNoise Ids/row numbers of Dataset: {name} =====\")\n",
    "    \n",
    "    # shape and type of dataset, 1 row and 101 columns ( total no.of iterations), ndarray\n",
    "    print(data.shape, type(data))\n",
    "    \n",
    "    # each column is: an array of subjectId, which are non-noise\n",
    "    print(\"first iteration subject ID's resulting non-noise\")\n",
    "    print(data[0][0].T)\n",
    "    \n",
    "DataName = ['COBRE']\n",
    "for i in DataName:\n",
    "    path = f'result/{i}_Count.mat'\n",
    "    data = load_result_matfile(path)\n",
    "    handle_count_dataset(i, data['count'][:])\n",
    "    print()\n",
    "    handle_nlctlabels_dataset(i, data['NLTCLabelS'][:])\n",
    "    print()\n",
    "    handle_nonNoise_dataset(i, data['nonNoiseDataInd'][:])\n",
    "    \n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8514ee74",
   "metadata": {},
   "source": [
    "### Typical Subjects ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef67027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: FBIRN Group: SZ\n",
      "shape: (99, 1) and type: <class 'numpy.ndarray'>\n",
      "Total no.of Typical Subjects:  99\n",
      "[  1   2   4   6   8  19  21  24  25  28  40  42  44  45  47  49  52  57\n",
      "  62  63  64  69  70  73  74  78  79  80  81  87  93  94  95  99 100 102\n",
      " 108 114 120 121 122 126 128 131 133 139 140 143 148 154 155 160 162 167\n",
      " 168 170 171 182 186 189 194 195 198 202 203 204 205 206 210 221 225 229\n",
      " 230 232 234 235 241 242 244 247 251 253 256 260 261 268 273 276 280 282\n",
      " 284 287 290 291 298 300 303 304 306]\n",
      "Dataset: FBIRN Group: HC\n",
      "shape: (92, 1) and type: <class 'numpy.ndarray'>\n",
      "Total no.of Typical Subjects:  92\n",
      "[  7  10  11  12  15  16  20  23  26  27  29  34  37  43  46  48  50  53\n",
      "  56  58  59  72  76  82  85  86  88  96  98 101 106 107 111 119 123 124\n",
      " 127 136 141 142 145 149 151 157 161 163 164 165 172 173 180 184 188 191\n",
      " 192 207 209 212 213 217 219 220 223 226 233 236 237 238 239 240 243 246\n",
      " 250 258 262 263 264 266 274 275 277 278 281 285 286 288 294 295 296 305\n",
      " 310 311]\n",
      "\n",
      "\n",
      "\n",
      "Dataset: COBRE Group: SZ\n",
      "shape: (55, 1) and type: <class 'numpy.ndarray'>\n",
      "Total no.of Typical Subjects:  55\n",
      "[  1   2   3   6   9  11  18  27  28  29  31  34  40  45  53  55  56  57\n",
      "  59  60  62  64  65  68  74  76  77  78  79  81  82  83  86  98 100 101\n",
      " 102 105 107 108 110 112 113 116 117 136 139 140 141 145 148 150 152 155\n",
      " 156]\n",
      "Dataset: COBRE Group: HC\n",
      "shape: (48, 1) and type: <class 'numpy.ndarray'>\n",
      "Total no.of Typical Subjects:  48\n",
      "[  4   5   7   8  10  12  14  15  20  21  22  25  26  35  36  37  39  41\n",
      "  43  46  47  50  52  61  63  67  71  85  88  90  94 103 104 111 114 115\n",
      " 120 121 122 126 128 129 130 133 138 147 151 157]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DataName = ['FBIRN', 'COBRE']\n",
    "\n",
    "def handle_typical_groups(name: str, group: str, data: h5py.Dataset):\n",
    "    print(f\"Dataset: {i}\", f\"Group: {group}\")\n",
    "    \n",
    "    # single row, consisting of subject ID's \n",
    "    # representing typical subjects after all the iteration \n",
    "    print(f\"shape: {data.shape} and type: {type(data)}\")\n",
    "    print(\"Total no.of Typical Subjects: \", data.shape[0])\n",
    "    \n",
    "    data = data.T[0]\n",
    "    \n",
    "    print(data)\n",
    "\n",
    "for i in DataName:\n",
    "    path= f'../result/round_0/{i}_Typ.mat'\n",
    "    data = load_result_matfile(path)\n",
    "    \n",
    "    handle_typical_groups(i, \"SZ\", data['TypIDG1'])\n",
    "    handle_typical_groups(i, \"HC\", data['TypIDG2'])\n",
    "    \n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858f3c78",
   "metadata": {},
   "source": [
    "### Score Analysis\n",
    "\n",
    "- Positive ⇒ subject looks more like COBRE’s SZ-typicals\n",
    "- Negative ⇒ subject looks more like COBRE’s HC-typicals\n",
    "- Zero ⇒ equidistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031ae839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Independent Score: FBIRN ========\n",
      "Shape: (311, 5) and type: <class 'numpy.ndarray'>\n",
      "top 5 subjects and there score comparing other dataset\n",
      "[[ 1.         -0.34937957  0.          0.         -0.34937957]\n",
      " [ 1.         -0.46927604  0.          0.         -0.46927604]\n",
      " [ 1.         -0.02209151  0.          0.         -0.02209151]\n",
      " [ 1.         -0.32279348  0.          0.         -0.32279348]\n",
      " [ 2.         -0.41399117  0.          0.         -0.41399117]]\n",
      "count of subjects having SZ:  173\n",
      "count of subjects who are healthy:  138\n",
      "======= Independent Score: COBRE ========\n",
      "Shape: (157, 5) and type: <class 'numpy.ndarray'>\n",
      "top 5 subjects and there score comparing other dataset\n",
      "[[-0.20494235  1.          0.          0.         -0.20494235]\n",
      " [-0.44445948  1.          0.          0.         -0.44445948]\n",
      " [-0.22080278  1.          0.          0.         -0.22080278]\n",
      " [ 0.06022404  2.          0.          0.          0.06022404]\n",
      " [ 0.53488137  2.          0.          0.          0.53488137]]\n",
      "count of subjects having SZ:  42\n",
      "count of subjects who are healthy:  115\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def handle_Indep_Score(name: str, data: h5py.Dataset):\n",
    "    print(f\"======= Independent Score: {name} ========\")\n",
    "    \n",
    "    # total subjects of current dataset name, then its classification comparing other dataset \n",
    "    print(f\"Shape: {data.shape} and type: {type(data)}\")\n",
    "    print(\"top 5 subjects and there score comparing other dataset\")\n",
    "    print(data[:5][:])\n",
    "    \n",
    "    total_subjects = data.shape[0]\n",
    "    avg_column = data[:, -1]\n",
    "    sz_subjects_count = np.count_nonzero(avg_column >= 0)\n",
    "    hc_subjects_count = np.count_nonzero(avg_column < 0)\n",
    "    print(\"count of subjects having SZ: \", sz_subjects_count)\n",
    "    print(\"count of subjects who are healthy: \", hc_subjects_count)\n",
    "    \n",
    "\n",
    "DataName = ['FBIRN', 'COBRE']\n",
    "for i in DataName:\n",
    "    path = f'result/{i}_Score.mat'\n",
    "    data = load_result_matfile(path)\n",
    "    handle_Indep_Score(i, data['IndepScore'][:])\n",
    "    # print('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
