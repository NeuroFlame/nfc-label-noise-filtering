{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faef2e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from matplotlib.font_manager import findSystemFonts\n",
    "from scipy.io import loadmat\n",
    "\n",
    "def iterate_group(data: h5py.Group, final_data: dict):\n",
    "    \"\"\"\n",
    "    Recursively iterate through a h5py Group and print its structure.\n",
    "    \"\"\"\n",
    "    for key in data.keys():\n",
    "        item = data[key]\n",
    "        if isinstance(item, h5py.Group):\n",
    "            final_data[key] = {}\n",
    "            iterate_group(item, final_data[key])\n",
    "        else:\n",
    "            final_data[key] = item[:]\n",
    "    return final_data\n",
    "\n",
    "def load_data_matfile(path: str, name: list[str]=[]):\n",
    "    with h5py.File(path, 'r') as f:\n",
    "        # List all groups in the file\n",
    "        # print(\"Keys in the file:\", list(f.keys()))\n",
    "        # Access the dataset\n",
    "        \n",
    "        if len(name) == 0:\n",
    "            data = {}\n",
    "            iterate_group(f, data)\n",
    "            return data\n",
    "        else:\n",
    "            result = {}\n",
    "            for key in name:\n",
    "                if isinstance(f[key], h5py.Group):\n",
    "                    # print(\"key is a group, iterating through it\")\n",
    "                    result[key] = iterate_group(f[key], {})\n",
    "                else:\n",
    "                    # print(\"key is a dataset, returning data\")\n",
    "                    data = f[key][:]\n",
    "                    data = data.T  # Transpose to match MATLAB's column-major order\n",
    "                    result[key] = data \n",
    "            return result\n",
    "\n",
    "def load_result_matfile(path: str):\n",
    "    data = loadmat(path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fab73bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset:  FBIRN\n",
      "(311, 1379)\n",
      "last column have the labels for each subject\n",
      "[1. 1. 1. 1. 2. 1. 2. 1. 2. 2.]\n",
      "count of SZ:  151\n",
      "count of Hc:  160\n",
      "\n",
      "\n",
      "\n",
      "Shape of the dataset:  COBRE\n",
      "(157, 1379)\n",
      "last column have the labels for each subject\n",
      "[1. 1. 1. 2. 2. 1. 2. 2. 1. 2.]\n",
      "count of SZ:  68\n",
      "count of Hc:  89\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "DataName = ['FBIRN', 'COBRE']\n",
    "\n",
    "for i in DataName:\n",
    "    content = load_data_matfile(f'data/{i}.mat', [i])\n",
    "    data = content[i]\n",
    "    \n",
    "    print('Shape of the dataset: ', i) # no.of subjects with features columns\n",
    "    print(data.shape)\n",
    "    \n",
    "    print('last column have the labels for each subject') # 1-SZ , 2-HC\n",
    "    last_column = data[:,-1]\n",
    "    print(last_column[:10])\n",
    "    \n",
    "    total_subjects = data.shape[0]\n",
    "    sz_count = np.count_nonzero(last_column == 1)\n",
    "    hc_count = total_subjects - sz_count\n",
    "    print('count of SZ: ', sz_count)\n",
    "    print('count of Hc: ', hc_count)\n",
    "    \n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd5a2d7",
   "metadata": {},
   "source": [
    "### non-noise rate from CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69ccc5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Count: COBRE =====\n",
      "Shape: (157, 4) and type of result: <class 'numpy.ndarray'>\n",
      "first 5 rows of the count matrix\n",
      "[[ 1.         81.         80.          0.98765432]\n",
      " [ 2.         86.         86.          1.        ]\n",
      " [ 3.         76.         75.          0.98684211]\n",
      " [ 4.         54.         54.          1.        ]\n",
      " [ 5.         62.         62.          1.        ]]\n",
      "\n",
      "====== NLCTLabels: COBRE =====\n",
      "Shape: (1, 101) and type of result: <class 'numpy.ndarray'>\n",
      "Each Column data shape:  (101,)\n",
      "first iteration, first 5 subjects label decision by 5 trees\n",
      "[array([[1, 0, 1, ..., 1, 0, 0],\n",
      "        [0, 1, 0, ..., 1, 1, 0],\n",
      "        [0, 1, 1, ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 0, 0, ..., 1, 0, 0],\n",
      "        [0, 1, 1, ..., 0, 1, 1],\n",
      "        [1, 1, 1, ..., 0, 0, 1]], shape=(108, 402), dtype=uint8)\n",
      " array([[0, 1, 1, ..., 0, 0, 1],\n",
      "        [0, 0, 0, ..., 0, 1, 1],\n",
      "        [1, 1, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 1, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 1, ..., 0, 0, 0]], shape=(108, 402), dtype=uint8)\n",
      " array([[0, 0, 0, ..., 1, 0, 0],\n",
      "        [0, 0, 0, ..., 1, 0, 1],\n",
      "        [1, 0, 0, ..., 0, 1, 1],\n",
      "        ...,\n",
      "        [1, 0, 1, ..., 0, 0, 0],\n",
      "        [0, 0, 1, ..., 0, 0, 0],\n",
      "        [0, 0, 1, ..., 0, 0, 0]], shape=(108, 402), dtype=uint8)\n",
      " array([[1, 1, 0, ..., 0, 0, 1],\n",
      "        [0, 1, 0, ..., 1, 0, 0],\n",
      "        [0, 1, 1, ..., 1, 1, 0],\n",
      "        ...,\n",
      "        [1, 1, 1, ..., 0, 0, 1],\n",
      "        [0, 0, 1, ..., 0, 0, 0],\n",
      "        [0, 0, 1, ..., 1, 0, 1]], shape=(108, 402), dtype=uint8)\n",
      " array([[1, 0, 0, ..., 0, 1, 1],\n",
      "        [0, 1, 0, ..., 0, 0, 1],\n",
      "        [0, 1, 1, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1, ..., 0, 0, 0],\n",
      "        [1, 1, 1, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 1, 0]], shape=(108, 402), dtype=uint8)]\n",
      "\n",
      "====== NonNoise Ids/row numbers of Dataset: COBRE =====\n",
      "(1, 101) <class 'numpy.ndarray'>\n",
      "first iteration subject ID's resulting non-noise\n",
      "[[  1 112 101  56 152  59  31  53  18  76  81  34 150   6 107 145  98  28\n",
      "  155  11 108  68 139 100  83 113 110  78  57  27  65  40  77   2  60   3\n",
      "    9 116  62  29 141 117 102  74  43 111  22  41  47  39 104  90  63   5\n",
      "   99  71  50  12 143  67  92 151   4 129  26  36  88  61 122   8  85  96\n",
      "    7  84 133 103  35  15 130 147]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "def handle_count_dataset(name: str, data: h5py.Dataset):\n",
    "    print(f\"====== Count: {name} =====\")\n",
    "    \n",
    "    # Shape of the opbject and type of it : (311, 4) and ndarray\n",
    "    \"\"\"\n",
    "        1st column: subject Ids\n",
    "        2nd total no.of times it sampled\n",
    "        3rd total no.of times it is non-noised\n",
    "        4th % of non-noise labelled\n",
    "    \"\"\"\n",
    "    print(f\"Shape: {data.shape} and type of result: {type(data)}\")\n",
    "    \n",
    "    print(\"first 5 rows of the count matrix\")\n",
    "    print(data[:5])\n",
    "    \n",
    "def handle_nlctlabels_dataset(name: str, data: h5py.Dataset):\n",
    "    print(f\"====== NLCTLabels: {name} =====\")\n",
    "    \n",
    "    # Shape and type: 1 row and 101 columns ( total no.of iterations) , ndarray\n",
    "    print(f\"Shape: {data.shape} and type of result: {type(data)}\")\n",
    "    \n",
    "    # each column is again a sampled no of rows x 2*ntrees columns\n",
    "    print(\"Each Column data shape: \", data[0].shape) # (216, 402)\n",
    "    \n",
    "    # print 5 tree output for 5 sampled subjects in 1st iteration.\n",
    "    # gives each tree decision label, 1->noise, 0 - non-noise\n",
    "    print(\"first iteration, first 5 subjects label decision by 5 trees\")\n",
    "    print(data[0][:][:5])\n",
    "\n",
    "def handle_nonNoise_dataset(name: str, data: h5py.Dataset):\n",
    "    print(f\"====== NonNoise Ids/row numbers of Dataset: {name} =====\")\n",
    "    \n",
    "    # shape and type of dataset, 1 row and 101 columns ( total no.of iterations), ndarray\n",
    "    print(data.shape, type(data))\n",
    "    \n",
    "    # each column is: an array of subjectId, which are non-noise\n",
    "    print(\"first iteration subject ID's resulting non-noise\")\n",
    "    print(data[0][0].T)\n",
    "    \n",
    "DataName = ['COBRE']\n",
    "for i in DataName:\n",
    "    path = f'result/{i}_Count.mat'\n",
    "    data = load_result_matfile(path)\n",
    "    handle_count_dataset(i, data['count'][:])\n",
    "    print()\n",
    "    handle_nlctlabels_dataset(i, data['NLTCLabelS'][:])\n",
    "    print()\n",
    "    handle_nonNoise_dataset(i, data['nonNoiseDataInd'][:])\n",
    "    \n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8514ee74",
   "metadata": {},
   "source": [
    "### Typical Subjects ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aef67027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: FBIRN Group: SZ\n",
      "shape: (99, 1) and type: <class 'numpy.ndarray'>\n",
      "Total no.of Typical Subjects:  99\n",
      "[[  1   2   4   6   8  19  21  24  25  28  40  42  44  45  47  49  52  57\n",
      "   62  63  64  69  70  73  74  78  79  80  81  87  93  94  95  99 100 102\n",
      "  108 114 120 121 122 126 128 131 133 139 140 143 148 154 155 160 162 167\n",
      "  168 170 171 182 186 189 194 195 198 202 203 204 205 206 210 221 225 229\n",
      "  230 232 234 235 241 242 244 247 251 253 256 260 261 268 273 276 280 282\n",
      "  284 287 290 291 298 300 303 304 306]]\n",
      "Dataset: FBIRN Group: HC\n",
      "shape: (92, 1) and type: <class 'numpy.ndarray'>\n",
      "Total no.of Typical Subjects:  92\n",
      "[[  7  10  11  12  15  16  20  23  26  27  29  34  37  43  46  48  50  53\n",
      "   56  58  59  72  76  82  85  86  88  96  98 101 106 107 111 119 123 124\n",
      "  127 136 141 142 145 149 151 157 161 163 164 165 172 173 180 184 188 191\n",
      "  192 207 209 212 213 217 219 220 223 226 233 236 237 238 239 240 243 246\n",
      "  250 258 262 263 264 266 274 275 277 278 281 285 286 288 294 295 296 305\n",
      "  310 311]]\n",
      "\n",
      "\n",
      "\n",
      "Dataset: COBRE Group: SZ\n",
      "shape: (55, 1) and type: <class 'numpy.ndarray'>\n",
      "Total no.of Typical Subjects:  55\n",
      "[[  1   2   3   6   9  11  18  27  28  29  31  34  40  45  53  55  56  57\n",
      "   59  60  62  64  65  68  74  76  77  78  79  81  82  83  86  98 100 101\n",
      "  102 105 107 108 110 112 113 116 117 136 139 140 141 145 148 150 152 155\n",
      "  156]]\n",
      "Dataset: COBRE Group: HC\n",
      "shape: (48, 1) and type: <class 'numpy.ndarray'>\n",
      "Total no.of Typical Subjects:  48\n",
      "[[  4   5   7   8  10  12  14  15  20  21  22  25  26  35  36  37  39  41\n",
      "   43  46  47  50  52  61  63  67  71  85  88  90  94 103 104 111 114 115\n",
      "  120 121 122 126 128 129 130 133 138 147 151 157]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DataName = ['FBIRN', 'COBRE']\n",
    "\n",
    "def handle_typical_groups(name: str, group: str, data: h5py.Dataset):\n",
    "    print(f\"Dataset: {i}\", f\"Group: {group}\")\n",
    "    \n",
    "    # single row, consisting of subject ID's \n",
    "    # representing typical subjects after all the iteration \n",
    "    print(f\"shape: {data.shape} and type: {type(data)}\")\n",
    "    print(\"Total no.of Typical Subjects: \", data.shape[0])\n",
    "    print(data.T)\n",
    "\n",
    "for i in DataName:\n",
    "    path= f'result/{i}_Typ.mat'\n",
    "    data = load_result_matfile(path)\n",
    "    \n",
    "    handle_typical_groups(i, \"SZ\", data['TypIDG1'])\n",
    "    handle_typical_groups(i, \"HC\", data['TypIDG2'])\n",
    "    \n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858f3c78",
   "metadata": {},
   "source": [
    "### Score Analysis\n",
    "\n",
    "- Positive ⇒ subject looks more like COBRE’s SZ-typicals\n",
    "- Negative ⇒ subject looks more like COBRE’s HC-typicals\n",
    "- Zero ⇒ equidistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031ae839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Independent Score: FBIRN ========\n",
      "Shape: (311, 5) and type: <class 'numpy.ndarray'>\n",
      "top 5 subjects and there score comparing other dataset\n",
      "[[ 1.         -0.34937957  0.          0.         -0.34937957]\n",
      " [ 1.         -0.46927604  0.          0.         -0.46927604]\n",
      " [ 1.         -0.02209151  0.          0.         -0.02209151]\n",
      " [ 1.         -0.32279348  0.          0.         -0.32279348]\n",
      " [ 2.         -0.41399117  0.          0.         -0.41399117]]\n",
      "count of subjects having SZ:  173\n",
      "count of subjects who are healthy:  138\n",
      "======= Independent Score: COBRE ========\n",
      "Shape: (157, 5) and type: <class 'numpy.ndarray'>\n",
      "top 5 subjects and there score comparing other dataset\n",
      "[[-0.20494235  1.          0.          0.         -0.20494235]\n",
      " [-0.44445948  1.          0.          0.         -0.44445948]\n",
      " [-0.22080278  1.          0.          0.         -0.22080278]\n",
      " [ 0.06022404  2.          0.          0.          0.06022404]\n",
      " [ 0.53488137  2.          0.          0.          0.53488137]]\n",
      "count of subjects having SZ:  42\n",
      "count of subjects who are healthy:  115\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def handle_Indep_Score(name: str, data: h5py.Dataset):\n",
    "    print(f\"======= Independent Score: {name} ========\")\n",
    "    \n",
    "    # total subjects of current dataset name, then its classification comparing other dataset \n",
    "    print(f\"Shape: {data.shape} and type: {type(data)}\")\n",
    "    print(\"top 5 subjects and there score comparing other dataset\")\n",
    "    print(data[:5][:])\n",
    "    \n",
    "    total_subjects = data.shape[0]\n",
    "    avg_column = data[:, -1]\n",
    "    sz_subjects_count = np.count_nonzero(avg_column >= 0)\n",
    "    hc_subjects_count = np.count_nonzero(avg_column < 0)\n",
    "    print(\"count of subjects having SZ: \", sz_subjects_count)\n",
    "    print(\"count of subjects who are healthy: \", hc_subjects_count)\n",
    "    \n",
    "\n",
    "DataName = ['FBIRN', 'COBRE']\n",
    "for i in DataName:\n",
    "    path = f'result/{i}_Score.mat'\n",
    "    data = load_result_matfile(path)\n",
    "    handle_Indep_Score(i, data['IndepScore'][:])\n",
    "    # print('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
