{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "797ec114",
   "metadata": {},
   "source": [
    "### Converting Original Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06bdfdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "from scipy.io import loadmat, savemat\n",
    "from enum import Enum\n",
    "from math import floor\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f480738",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "772e8a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_utf16_array(array):\n",
    "    \"\"\"Decode MATLAB UTF-16 encoded uint16 arrays to strings.\"\"\"\n",
    "    array = array.flatten() if array.ndim == 2 else array\n",
    "    return ''.join(chr(c) for c in array if c != 0)\n",
    "\n",
    "\n",
    "def handle_cell_string_dataset(dataset, file_handle):\n",
    "    \"\"\"Handle MATLAB-style cell array of strings stored as references.\"\"\"\n",
    "    result = []\n",
    "    for i in range(dataset.shape[0]):\n",
    "        ref = dataset[i, 0]\n",
    "        deref = file_handle[ref]\n",
    "        value = deref[()]\n",
    "        if isinstance(value, bytes):\n",
    "            result.append(value.decode('utf-8'))\n",
    "        elif isinstance(value, np.ndarray) and value.dtype == np.uint16:\n",
    "            result.append(decode_utf16_array(value))\n",
    "        else:\n",
    "            result.append(value)\n",
    "    return result\n",
    "\n",
    "def iterate_group(data: h5py.Group, final_data: dict):\n",
    "    \"\"\"\n",
    "    Recursively iterate through a h5py Group and print its structure.\n",
    "    \"\"\"\n",
    "    for key in data.keys():\n",
    "        item = data[key]\n",
    "        if isinstance(item, h5py.Group):\n",
    "            final_data[key] = {}\n",
    "            iterate_group(item, final_data[key])\n",
    "        else:\n",
    "            final_data[key] = item[:]\n",
    "    return final_data\n",
    "\n",
    "def load_data_matfile(path: str, name: list[str]=None):\n",
    "    data = None\n",
    "    with h5py.File(path, 'r') as f:\n",
    "        # List all groups in the file\n",
    "        # print(\"Keys in the file:\", list(f.keys()))\n",
    "        # Access the dataset\n",
    "\n",
    "        if len(name)==0:\n",
    "            data = {}\n",
    "            iterate_group(f, data)\n",
    "            return data\n",
    "        else:\n",
    "            result = {}\n",
    "            for key in name:\n",
    "                if isinstance(f[key], h5py.Group):\n",
    "                    # print(\"key is a group, iterating through it\")\n",
    "                    result[key] = iterate_group(f[key], {})\n",
    "                elif key == 'FILE_ID':\n",
    "                    result[key] = handle_cell_string_dataset(f[key], f)\n",
    "                else:\n",
    "                    # print(\"key is a dataset, returning data\")\n",
    "                    data = f[key][:]\n",
    "                    data = data.T  # Transpose to match MATLAB's column-major order\n",
    "                    result[key] = data \n",
    "            return result\n",
    "        \n",
    "def load_result_matfile(path: str):\n",
    "    data = loadmat(path)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8631a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SourceDataKeys(Enum):\n",
    "    \"\"\"\n",
    "    Enum to represent different keys in the original mat file.\n",
    "    \"\"\"\n",
    "    FILE_ID = 'FILE_ID'\n",
    "    ANALYSIS_ID = 'analysis_ID'\n",
    "    ANALYSIS_SCORE = 'analysis_SCORE'\n",
    "    SFNC = 'sFNC'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6342f411",
   "metadata": {},
   "source": [
    "### Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62a7ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_fnc_to_features(fnc_path: str, dest_path: str, name: str):\n",
    "    file_path = os.path.join(fnc_path, f'{name}.mat')\n",
    "    original_data = load_data_matfile(\n",
    "        file_path,\n",
    "        name=[\n",
    "            SourceDataKeys.SFNC.value,\n",
    "            SourceDataKeys.FILE_ID.value,\n",
    "            SourceDataKeys.ANALYSIS_SCORE.value,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # --- find diagnosis column (case-insensitive) ---\n",
    "    file_ids = original_data[SourceDataKeys.FILE_ID.value]\n",
    "    label_index = next(\n",
    "        (i for i, col in enumerate(file_ids) if \"diagnosis\" in col.lower()),\n",
    "        None\n",
    "    )\n",
    "    if label_index is None:\n",
    "        raise ValueError(f'No \"diagnosis\" column found in FILE_ID for {name}')\n",
    "\n",
    "    labels = original_data[SourceDataKeys.ANALYSIS_SCORE.value][:, label_index]\n",
    "    # Optional: match MATLAB’s strict check\n",
    "    # uniq = np.unique(labels)\n",
    "    # if not np.all(np.isin(uniq, [1, 2])):\n",
    "    #     raise ValueError(f\"Unexpected diagnosis codes: {uniq.tolist()}\")\n",
    "    labels = labels.reshape(-1, 1)\n",
    "\n",
    "    fnc_matrices = original_data[SourceDataKeys.SFNC.value]  # shape: (N, P, P)\n",
    "    N, P, _ = fnc_matrices.shape\n",
    "\n",
    "    # --- build the lower-triangle mask excluding diagonal (k=-1) ---\n",
    "    mask = np.tril(np.ones((P, P), dtype=bool), k=-1)  # P x P\n",
    "\n",
    "    # --- replicate MATLAB's column-major flattening ---\n",
    "    # 1) reshape each P×P to length P*P along Fortran (column-major) order\n",
    "    # 2) take the linear indices where mask is True, also in Fortran order\n",
    "    linear_idx = np.where(mask.ravel(order='F'))[0]           # size: P*(P-1)/2\n",
    "    fnc_flat_F = fnc_matrices.reshape(N, P * P, order='F')    # N x (P*P)\n",
    "\n",
    "    source_data = fnc_flat_F[:, linear_idx]                   # N x (P*(P-1)/2)\n",
    "    # keep dtype default (float64) to match MATLAB; or cast if you prefer\n",
    "    # source_data = source_data.astype(np.float64, copy=False)\n",
    "\n",
    "    # append labels as the last column\n",
    "    out = np.hstack([source_data, labels])\n",
    "\n",
    "    # save with variable name = dataset name (like MATLAB)\n",
    "    out_path = os.path.join(dest_path, f'{name}.mat')\n",
    "    savemat(out_path, {name: out}, do_compression=True)\n",
    "\n",
    "\n",
    "for i in [\"FBIRN\", \"COBRE\"]:\n",
    "    fnc_dataset = convert_fnc_to_features(\"../original_dataset\", \"dataset\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b97418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMETERS\n",
    "SamplingThs = 0.7\n",
    "iter = 101\n",
    "ntree = 201\n",
    "NI_threshold = 2\n",
    "TypThs = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9e78fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import complete_random_forest.crf as crf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e879f5c",
   "metadata": {},
   "source": [
    "### Running CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3b2f61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing No. 1 CRF for FBIRN dataset\n",
      "sampling indexes:  [253 181  17 127  86 138  44  63 278   3 205 255 101 153 131 185 217 139\n",
      " 267 167 260  72  39 220   0 130  61 137 180 299 207 169  51  70   5 103\n",
      "   2 102  18 246 184  88 224 227 228  23 173 147  96 266   1  77  98 305\n",
      "  16  69 155 240  65 281 215 166 213 229 201 170 234 298 119 114  56  73\n",
      " 194 252  64  46 243  78 307 128  99 226 259  79 241 210  24  41 290 107\n",
      " 271 200 188 151 301 303 154 125 120  59 136 289 176  68  48 231 193 182\n",
      " 157  58 223 164 236  14 192  50   6  52 263 238  81 291 242 195  26 277\n",
      " 294 284 244 124 285 270 145 163  97 187 196 280 199 104 141 251 162 190\n",
      "  83 189 216 309 208 152 160 179 118 287 177   4  34 110  12 221  95  42\n",
      " 111 218 310 222 115 235  75  53  89 225 292 106  60 198 265  40  31  22\n",
      "  11  10 171 168 135 219 245  47 257  36  82  67 140   8  55 212 158  84\n",
      " 254  38 186 206 304  32 100 239 296  54 150 308 183 126 112 276 262  74]\n",
      "picked sampling number:  [ 17 127  86 138  44  63   3 205 255 153 185 217 260  72  39   0 130  61\n",
      " 137 299 169  51  70   5 103   2 102  18 246  88 224 228  23 147  96 266\n",
      "   1  77  98  69 240  65 281 166 229 201 170 234 298 119  56  73 194 252\n",
      " 243  78 128  99 259  79 241  41 290 107 200 151 301 303 154 125 120  59\n",
      " 289 176  68  48 231 193  58 223 164 236  14 192  52 263 238  81 291 242\n",
      "  26 277 294 284 244 124 285 163  97 187 280 199 104 141 251 190 216 309\n",
      " 160 179 118  34 110  12  95  42 218 310 222 235  75  89 225 106 198 265\n",
      "  40  22  11  10 135 219 245  47 257  36  67 140  55 212  84 254  38 206\n",
      " 304 100 239 150 183 276]\n",
      "Constructing No. 2 CRF for FBIRN dataset\n",
      "sampling indexes:  [269 300 298 139 159 120 184 173 299 303   1 290  73  16 305 167 193 209\n",
      "  80  98 161  92 282   0 213 180  62 155  56 154  94 194 281 114  72 182\n",
      " 136  88  17  70  77 233 176 203  61 121 181 109 210  29 246 224 256 101\n",
      " 178 289 131  69 297 133   2  99  27 103 283  79  30 170   5 107  86 240\n",
      " 258 130 253  23 259 202 301  43  41  44 226 231 228 125 197 146 260  68\n",
      " 205 227  48   3 307  78 207 241 166  64 185 147 142 250 201 127  93  51\n",
      " 206  76 189  90  35 126  89 111 122 179  34 232 198  81  38 105 218 171\n",
      " 268 140  53 112 208 257   6 277 236  10  60 110 288  40 230 239 309 265\n",
      "  13 245 291 152  11 117 242 273 216 134 308 116  54 199 244  19 261 106\n",
      " 212 168  97 187 157   4 274  31 160  83  87 175  21  50 304 222 292  58\n",
      "  74  67 238 118 280  52 295 270  37 186 123  82 192 115 211 158 293 141\n",
      " 248 124  22 262 162 174 190 264 276 310 237 150 163  49  95  33 296 214]\n",
      "picked sampling number:  [300 139 159 184 303   1 290  73  16 305 167 193 209  80  98 161  92 282\n",
      "  62  94 194 281  72  88  17  77 233 203  61 246 224 101 178 289 131 297\n",
      " 133   2  99  27  79   5  86 240 253  23 259 202  43  41  44 231 228 125\n",
      " 197 260  68 205  48   3  78 241 166 185 147 142 250 201 127  93  51 206\n",
      "  76 111 122 179 232 198  81 105 218 171 140  53 208 257   6 277 236  10\n",
      " 110  40 230 309 265 245  11 117 242 273 134  54 244  19 261 106 212 168\n",
      "  97 187   4 274  31  87 304 222  58  74 238 118 280  52 295 270 123  82\n",
      " 192 293 141  22 162 190 310 237 163  49  95  33 214]\n",
      "Constructing No. 3 CRF for FBIRN dataset\n",
      "sampling indexes:  [ 66 298  63 224  92  93   0 283 209 246  17 125 137  64  65 139 136  46\n",
      " 269  80 203   1 173  98 303  99  41 114 200 132 233 138  62 103 278 133\n",
      " 256 282   3  56 154 182 252 180 121 217  43 227 279 213 271 201 167 185\n",
      " 155 215 176 188 220   2  27  30  78 107 197  44 241 253  70 170 109  94\n",
      " 159 127  23 128 229 204 243 210 228 130  39  86  51 247  96 147  77  69\n",
      "  16 289 234 194 297 255 153 281 250 205 101  29  48 161 258 305  24 299\n",
      " 238 287 236 232 249 144  50 219  67 230  15  52 295 140 148 211  36 124\n",
      " 163 123 261 218  76 304  42 212  28 225 309  49  87 129 306  12 189 168\n",
      "  71  47 274 191  35 265 143 277 285 175 293 100  85  33 106 117 245  84\n",
      " 221 263 141  97 254 264  90 223  60   6 276 105  81 308 251 292 110  75\n",
      " 158 172   9  19 187 196 280 192 257  11 222  53  13  34 239 108 262 199\n",
      "  89 160  95 174 235 206 270  91 152 115  10 284 162  32  37 310 134 118]\n",
      "picked sampling number:  [298  63 224  92  93 283 209 246 125 137 139 136  46 269 203   1 303  99\n",
      "  41 132 233 138  62 133   3  56 154 121 217 279 271 201 167 185 220   2\n",
      "  27  30  78 107 197  70 170 109  94 159 127  23 128 229 204 243 228  39\n",
      "  86 247 147  77  69 289 234 194 297 255 153 281 250 205 101 161 305  24\n",
      " 299 238 287 236 232 249 144 219 230  52 295 140 148  36 163 123 261 218\n",
      " 304  42 212  28 225  49  87 129 189  71  47 274 265 277 285 175 293 100\n",
      "  85  33 106 245  84 263 141 254 264 223   6 276 105  81 110  75 172   9\n",
      "  19 187 280 257 222  53 239 262 199 160  95 235 206 152  10 284 162  37\n",
      " 310 118]\n",
      "Constructing No. 4 CRF for FBIRN dataset\n",
      "sampling indexes:  [ 73 272  93 253  30 130 137 229  41 256  68 188  70 159 299 154 289 226\n",
      "  72 215  29 197 307 201 193 209 210 250 205 279  16 207 133 102 138 227\n",
      "  44 185  77 165   2 290   7  24 166   0 282  88  62 246  48 233 228  56\n",
      " 266 281 204  46 301 303 283   1 101 255  86 258 113 202  94 252  98  80\n",
      " 269 178 194 109 155 271 298  66  61  63 278 231  59 240 114 107 203 241\n",
      " 142  64 161 259 146 139 300 121 119 286 184  20 169 305 297  39 167   3\n",
      " 141 270 190  12 273 221 104 244 280  13 242   4 152 288 196 225 162 106\n",
      " 192  49 124   9 163  19 183 117  76 223 294   6  40 268 219 122  58  11\n",
      "  95 195  32 160 129  37 111 164 126 168  67 145 206 177 285 238 232 264\n",
      "  50  90 148 175  28 186  87 235 304  35 174 140  14 187 150 198  25  71\n",
      "  10 191  38 292  42 296  55 208  26 236  81 110  54  97  33 212  31 287\n",
      "  91  45 108 123  53 199 149  74 172  84  22  82 118 134 262 245 143  34]\n",
      "picked sampling number:  [ 73 272  93 229  41  68 188 159 299 154 289 201 193 209 250 205 279 102\n",
      " 138  44 185  77 290   7  24 166   0 246  48 233 228  56 281 204  46 303\n",
      " 283   1 101 255  86 113 202  94 252  98  80 178 109 155  63 231 240 107\n",
      " 203 241 142 161 259 139 119 286  20 297  39 167   3 141 190 273 104 244\n",
      " 280 242 288 225 162 106 192 124   9 163  19 183 117  76 223 294   6 268\n",
      " 219 122  58  11  95 160 129 111 164 126 206 285 238 232 264 148 175  28\n",
      "  87 235 304 140 187 150 198  25  71  10 191  38  42 296  55  26 110  54\n",
      "  97  33 212 287  45 123 172  84  22 118 134 245 143]\n",
      "Constructing No. 5 CRF for FBIRN dataset\n",
      "sampling indexes:  [286 234 121 133 202 250 147 247 193 224 272 213 289 125   3   7   0 302\n",
      "  73 303 260 120 119  70  63  51 159 153  77 197 299 165  80  16 205 297\n",
      "  99 267 167 200 228 269  48 240 107 109 246  69 300  66 220 253  59 178\n",
      " 138 128 271 146 233 136 142 127   2 266 182 101 279 290  86  29 137 217\n",
      "  41 170 305  61 258  20 281 226  93 154 301 166 103 241 102 282 181 278\n",
      "  68 307 283  23 204 130 155 169 188  62 243 173 131 255  94  44  65 185\n",
      " 152 198 118 222 126  71 150 212  13  87  89 211   6 135 276 264  25  12\n",
      " 293 124 175  97 123 116 254  26  14 248 168 105 232 284 145  37  11 242\n",
      " 141 310 122  81  55 156  75 108 257 143 294 219 160  33  52 261 158  40\n",
      " 236  34 208 148 174 117 270 251 235 244 179 157  31 245 199  38  60 177\n",
      "  49 277 274 265 192 214  57 172  45  76 129  67 268  82 288 238 273  21\n",
      "  10 110 186 163 218 223 100  15  50 134 306 295 195 304 225 291 171  42]\n",
      "picked sampling number:  [286 234 121 133 202 250 147 193 224 272 125   3   7   0 302  73 303 260\n",
      " 120 119  70  63  51 159 153  77 197 165  80 205 297  99 267 167 228  48\n",
      " 240 107 246  69 220 178 138 128 233 136 142 127   2 101 279 290  86 217\n",
      "  41 170  61  20 281  93 154 166 103 241 102 181  68 283 204 169 188  62\n",
      " 243 131 255  94  44  65 185 198 118 222  71 150 212 211   6 135 276 264\n",
      "  25  12 293 124  97 123  26  14 232 284  11 242 141 310 122  81 156  75\n",
      " 257 294 219 160  33  52 261  40 236 208 148 270 251 235 179 245 199  38\n",
      " 277 274 265 192 214  57 172  45  76 238  10 110 163 218 100  15 134 306\n",
      " 295 304 225 171  42]\n",
      "Constructing No. 6 CRF for FBIRN dataset\n",
      "sampling indexes:  [ 56 166 289 176 307  88 147 220 130 103   2   7 202 173 120  23  86  96\n",
      " 227 217 181 243 125  48 133 213 188 201  18 281 121   1 197   3 138 153\n",
      "  41  30  78   0  64 260 303  92 142 229  65 215 226  79 269 272  17 155\n",
      " 205 267 107 165  66 210  93 271  69  77 131 203  94 137 207 299  43 301\n",
      " 167 194  59 290  80 204 241  99 305  24 258 253 250 193  20  61 283  16\n",
      "  62 247 200   5 240 102  73 151 233 209 101 154 256  51 139 136  70 113\n",
      " 263  37 306 144  15  57 270 126 276 150  97  87 222 232 304 157 183 237\n",
      " 134 186  52   8 262 292 225  95  35 244 104 187  58 124 163 122 174  74\n",
      " 261 293  33 284  36  71 177 112  32 118 211 268  40 206 199  11 273 191\n",
      " 196 254  21 171 129  82 179 145 265 156 294 152 257  45 285 100 140  50\n",
      "  10 221 277 235 168  47  89  85 236 198 308  76 238 123  75 291  19 189\n",
      " 115 208 242  34 108 309 105 172 149 164 212 141 287 117   6 248   9 135]\n",
      "picked sampling number:  [ 56 166 289  88 147 130   2   7 202 120  23  86 217 243 125  48 188 201\n",
      "  18 281 121   1 197   3 138 153  41  78   0  64 260  92 142 229  65  79\n",
      " 272  17 155 205 267 107  93  69  77 203  94 137 299  43 167 194  59 290\n",
      "  80 204 241  99 305  24 253 250 193  20  61 283  62 247 200   5 240 102\n",
      "  73 233 209 101  51 139 113 263 306  15  57 270 126 276 150  97  87 222\n",
      " 232 304 183 237  52   8 262 225  95 244 104 187  58 124 163 122  74 261\n",
      " 293  33 284  36  71 112 118 211 268 206 199  11 273 191 171 179 265 156\n",
      " 294 257  45 285 100 140  10 221 235 168  47  85 236 308  76 238 123  75\n",
      "  19 208 242  34 309 172 164 212 141 287 117 248   9 135]\n",
      "Constructing No. 7 CRF for FBIRN dataset\n",
      "sampling indexes:  [269 137  39  56  29  96  68 165 203  16 176 119 109  93 182  78 131 231\n",
      " 121   2 247 215 147 224 283 275 200 210  86   3  64  65 252  27  62 159\n",
      " 133   5 234 290   1  61 194 253 180 278 154 255  80 213 166 153 120 185\n",
      " 170 169 103 151  41 272 220 241  72  63  44  92 305 146 240 233 113 127\n",
      " 202 289 250 130 229 114 286  77 282 228 197  70 193  94 281  73 188  69\n",
      " 297 142 102 266 101 299 204 125 226 139 184  99  59  98  17 307 107 205\n",
      "  52  90 262  38  36  32 219  26 280 276  76 171 144  40 292  35  82  55\n",
      " 261 177 162  53 140 123 134 274 270  71 273 277 214  37 211 115 192  89\n",
      " 310 306  19 294 110   6 163 141 168 263  84 232  10 238  22 135 160 148\n",
      " 239 206 105 190 186 196  67  95 235  34  13 152  31 116 106 179 122 195\n",
      " 108 126 254  58 265 285  85  45 245 223 309 198  50 124  42   4 284 118\n",
      " 264  57 129 164  81 295 183 149 187 287 145 268 288 156 112 308 242 199]\n",
      "picked sampling number:  [ 39  56 165 203 119  93 182  78 231 121 147 224 200  86   3  65 252  27\n",
      "  62 159 133   5 234 290   1 194 253 154 255  80 153 185 169  41 272 241\n",
      "  72  63  44  92 305 240 233 113 127 202 289 250 229 286 228 197 193  94\n",
      " 281  73 188  69 297 142 101 204 125 139 184  99  59  98 107 205  52  90\n",
      " 262  38  36 219  26 280  76 171 144  40  55 261 177 162 140 123 134 274\n",
      " 270  71 273 277 214  37 211 192 310 306  19 294 110   6 163 141 263  84\n",
      " 232  10 238  22 135 160 148 206 105 190 196  95 235 116 106 122 108 126\n",
      " 254  58 265 285  85  45 245 309  42 284 118  57 129 164  81 295 183 187\n",
      " 287 268 112 242 199]\n",
      "Constructing No. 8 CRF for FBIRN dataset\n",
      "sampling indexes:  [176  59 209 231 279   1 109   3  72   0  23 258  86 220  62  18 173 266\n",
      " 103  64   5 215 102 201 136  17  30  24  88 247 298 121 178 133  80  98\n",
      " 302 226 299 181  48 188 166 127 130  20 240  43  77  93 154 107 113 184\n",
      " 253 228 146 128  65 170 203 289 241 194 281  79  39  44  29 286 155  99\n",
      " 147 182 307 161  69 197 290 227 193 132 185 275 303 269 283 272 159 243\n",
      "  73 217  70 233 114 300 204  61  41  46 213 125 297 169 101 246   2 271\n",
      " 284 115  60  71 222 148 150 149  15  40 129  31 242 110  22 162 104  38\n",
      " 164 280  58  83 118  82 189 230 274 140 306 122  53 160 196  81 214 191\n",
      " 177 285  21 270 287 195 288 218 190 158  45 206 112 156 276 186 295 216\n",
      " 292 236 211   8  37  85  36  42 245  55 117 134 277 171 239 106  84  89\n",
      " 183 238  57  26 264  35 273 198 293 100  52  34 168  50  87 251  76 157\n",
      " 268  25 221 225 296 308  90 244 265 235  14 254 124 174  33 111  75 223]\n",
      "picked sampling number:  [ 59 209 231 279   1   3  72  23  86  62 266 201  24  88 121  80  98 302\n",
      " 188 166 127 240  43  77 154 107 113 184 228 128  65 170 203 289 241 194\n",
      " 281  79  39  44 286  99 147 182 161 197 290 193 132 185 275 303 272 159\n",
      " 243  73  70 233 300 204  61  41  46 125 297 169 101 284  71 222 148 150\n",
      "  15  31 242 110  22 162 104  38 164 280  58 274 140 122 160  81 191  21\n",
      " 270 190  45 206 156 276 295 216 211  85  36  42 245 277 171 239 106  84\n",
      " 183  57  26 293 100  52  87  76 221 225 265 235 254  33  75]\n",
      "Constructing No. 9 CRF for FBIRN dataset\n",
      "sampling indexes:  [ 44 166  66 231 204 119 182 302 227  18 201   1  65 241  88  98 226   2\n",
      "  93 233 220 266   3 200 279  94 120  41 121 203 194 193 301 289 202 240\n",
      " 154 217  62 243  72 146  78 209 137 107 173 229   0 305 210 180 109  46\n",
      " 188  99 114 133 298 125 275 300  80 113  77 147 170 213  23 282 283  96\n",
      "  69 303 255  51 161 178 185 256 247 159 215 269 176 197 224 167  86 267\n",
      "  64  70 139 207 271 101 260 205 131 272 253  73 165  63 307 153 299  48\n",
      "   9 274 186 164 143 280 216 108 134 244 123 124 263 248 110  54  58 265\n",
      "  97 156  37 157 293  75 237 221  33 273  12 292 199 162  34 187 104  55\n",
      " 172  53  91 189 152 190  11 177 160 100 174 308  14 195  35 236 148 249\n",
      " 122  90 171 179 105 198 219 306 264  82 310 239 129 284  95  47 287  40\n",
      "  89   8  15 251 295 168 158  25 309 150 232  84 214 192  83 225 261 211\n",
      "  21 145 222 296 235 144 140 245  22 112 285 242   4  36 118 254  74 268]\n",
      "picked sampling number:  [ 44 166 204 119 302  18   1  98 226  93 233 220 279  94 120  41 121 194\n",
      " 289 202 240 154  62 243  78 107   0 305 109  46 188  99 125 275  80 113\n",
      "  77 147 170  23 282  69 303  51 161 185 247 159 224 167  86 267  64 139\n",
      " 101 260 205 131 272  73 153 299   9 274 186 164 143 280 134 244 123 263\n",
      " 248 110  54  58 265  97 156 293  75 237 221  33 273 199 162  34 187 104\n",
      "  55 172  53  91 152 190  11 160 100 174  14 236 148 249 122 171 179 105\n",
      " 198 219 306 264 310 239 284  95  47  15 251 295 168 158  25 309 150 232\n",
      "  84 214 192 225 261 211  21 222 235 144 140 245  22 112 285 242  36 118\n",
      "  74 268]\n",
      "Constructing No. 10 CRF for FBIRN dataset\n",
      "sampling indexes:  [260 193  78 282  69 197  96 120   3  30 176   1 182 302 253 159  72 133\n",
      "  27 256 278  88 194  98 290 240  43 201 233  86 281 258 178   0  29 113\n",
      " 307 250 114  79 271  70 127 289 166 130 184 213 305 299 121  51 217 101\n",
      "  16 142  56  46  62 231 137  24 188 147  92  63 167 297 131 215 128 139\n",
      " 300 173 103  41  68 146 247 200 181  48  39 228 132  18 209  99 252 151\n",
      " 286 266 269  66  23  44 259 165 241  80  94 279 153   2 169 275 109 246\n",
      " 145  35 126 177 152  25 304 270 208 216 163 104 248 214 288  55 172 168\n",
      " 225  76 292  85  97 273  11 129 160 219  26 196  36 221  33 251 149 308\n",
      " 158 287 239 310  12 164  14 122  83 276 117  49 211 108 195 171 175 236\n",
      "   4  42 144  57  28 238 206  67 264 280 249  71  58 212 118 150 245 223\n",
      "  90  75 235 148 262 230 277  34  40  38 140 274 294 261 105  60 124 222\n",
      " 296 112 263   9  52  31 257 116 254  82  22  50 143  54 306 199 157 141]\n",
      "picked sampling number:  [193  78 282 197 120   3   1 302 253 159  72 133  27  88 194  98 290 240\n",
      "  43 201 233  86 281   0 113 307 250  79 271 127 289 166 213 305 299  51\n",
      " 217 101 142  46  62 231  24 188 147  92  63 167 297 131 215 128 139  41\n",
      "  68 146 247 181  48  39 228 132  18 209  99 252  23  44 259 165 241  94\n",
      " 279 153   2 169 275 246 126  25 304 270 208 216 163 248 214  55 172 225\n",
      "  76  85  97 273  11 219  26  36  33 251 158 287 310  14 122  49 175 236\n",
      "  42  28 238 206  67 264 280 249  71  58 212 118 150 245  75 235 148 262\n",
      " 277  34  38 140 274 294 261 105 263   9  52  31 257 254  22 306 141]\n",
      "Constructing No. 1 CRF for COBRE dataset\n",
      "sampling indexes:  [100  23  61  47  17  54  55  16 109 105  56 151 144  80  12 147  76 116\n",
      " 107   5 154 140 101 149  39  64 134  97  30  31  10  27  41  99  77 135\n",
      "  50  85  82  58 138 111  33   1  52  26  75   8  53  73 155  81  72 112\n",
      " 131  93  11  66  42 133  43  94  45  48 125  46  69  86 145 103   7  51\n",
      "  35  14  84  32  98  70 126  18 102  92  37 123 128 113  62  22   4  24\n",
      "  74 120 108 153  21  96 110   6  49 130 118  68  60   9 127 136 142 152]\n",
      "picked sampling number:  [100  61  47  54 109 105  56 151 144  80 147  76 116 107 154 140 101 149\n",
      "  39  64  10  27  99  77 135  50  85  82  58 138 111  33  52  26   8 155\n",
      "  93  11  66  42 133  43  94  45  48 125  46  69 145 103   7  51  35  14\n",
      "  84  32  98  70 126 102  37 128 113  62  22   4  24  74 120  21  96 110\n",
      "   6  49 130 118  68  60   9 127 142 152]\n",
      "Constructing No. 2 CRF for COBRE dataset\n",
      "sampling indexes:  [  2  99 135  53  80  54   1  72  58  47 138 101 151  78  85  12 155 144\n",
      "   0  27  79  59  10 124  77 140  75  23  81  30   5 109 154 115  55  39\n",
      "  63 139  82 116 107   8  41  44 147 104  52  64  61 112  76  17  28  31\n",
      " 103 136  18  70 156  51 110  93 130  88  71  15  11 141  86  37  20  19\n",
      "  36  34 145 108  89  83  43  91   4 102 150 142   3  38 129  42   9 123\n",
      "  95  57 125  66 132  24 119  22 122  62 131 121 117  40   7  25 153 143]\n",
      "picked sampling number:  [ 99 135  80  54   1  72  47 138 101 151  78  85  12 155   0  27  79  59\n",
      "  10  77 140  75  81  30   5 115  55  39 139  82 116 107   8  41  44 104\n",
      "  64 112  76  17  28  31 103 156  51  93 130  88  15  11  86  19  36  34\n",
      " 108  83  91   4 102 150 142   3  38 129  42   9  95 125  66 132  24 119\n",
      "  22  62 121  40   7  25 153 143]\n",
      "Constructing No. 3 CRF for COBRE dataset\n",
      "sampling indexes:  [100  26  99 124   2  79  53  97  28 135  16  41  78  23  56  55  64 134\n",
      "  72 115 139  50  31  75 112  85  54  67  59 116  58   1 104  10 155   8\n",
      "  80 149 106  30  52  63 109  17  39 140 111  44 107 151  81  82  73  33\n",
      "  24 130  43 123 146 142  15  37 129  89 145  88  48 152  42  62 125  70\n",
      " 110 126   9  49 117  38  18  94  60 131 148   7  98  90  34  20   3  32\n",
      "  22 122  11  69  25 133 114  36 118 127  83  74  95 141  29  93 113  96]\n",
      "picked sampling number:  [ 26  99  79  28 135  78  55  64  72  50  75 112  85  54  59 116  58   1\n",
      " 104  10   8  80  30  52  63  17  39 140 111 151  81  82  73  33  24 130\n",
      " 123 146  15 129 145  88  42 125  70 110 126  49 117  38  94  60 131 148\n",
      "   7  98  90  34  20   3  32  22 122  11  25 133 114  36 127  83  95  29\n",
      "  93 113]\n",
      "Constructing No. 4 CRF for COBRE dataset\n",
      "sampling indexes:  [109   5  80 154  17  39  82  85  12  28  16 101  97 100 111  23  31 106\n",
      "  58  27 116 135  30 149 140  33  56  59 105 112  64  76 115  53 107  47\n",
      " 155  77 144 147  67   0 138  10  79   2   1 124 139  73  26  81  61  99\n",
      " 118  46 127 150  69  29 113  95  13  68   4  43  19 153  71  90  24  14\n",
      "  66  91 102  11 152  18  87   6 145 156  51  37   9  94  34 120 132  40\n",
      " 148  86  65  38 123 122 131  96  48  42  25  36 121  32 125 110   7  92]\n",
      "picked sampling number:  [109   5  80 154  17  39  82  85  28  97 111  31 106  58  27 116 135 149\n",
      " 140  56  59 105 112  64  76 107  47  77 144 147  67   0 138  10  79   1\n",
      " 139  73  26  81  61  99  46 127 150  29 113  95  13  68   4  43  19 153\n",
      "  71  90  24  14  66 102  11  87   6 145 156  51   9 120 132  40 148  65\n",
      "  38 122  48  42  25  36 121 110   7]\n",
      "Constructing No. 5 CRF for COBRE dataset\n",
      "sampling indexes:  [ 12  77  50 135 109  81  99  33  26  41  23 100 154  64 101  31 115  28\n",
      " 104  27 138 106  55  39  44  73 116   2  52  78 111  79 144 155 105  75\n",
      "   0  76  53  63 147  58 149  59 140 151  85  47 107  72   8  17 139  97\n",
      "  43  65  20 141  91  46  68 108  14  32 122  37 114 142  66 148 113  42\n",
      "  21  11 152  51 133  25   4  70 143  29  38  95 121   9 126  83  36 103\n",
      " 146 136  93 153  62 130  60 118   6 131  19  57  88  92  74  96 150  48]\n",
      "picked sampling number:  [135 109  81  33  26  64 101 115  28 104  27 138 106  55  39  44  73 116\n",
      "  78  79 144 155 105  75  76  63 147 149  59 140 151  85 107  72   8 139\n",
      "  97  20 141  91  46 108  14 122  37 114 142  66 148 113  42  21  11 152\n",
      "  51  25   4  70  29  38  95 121   9 126  83  36 103 146 136  93 153  60\n",
      "   6  19  57  88  74 150]\n",
      "Constructing No. 6 CRF for COBRE dataset\n",
      "sampling indexes:  [ 79  23 147 151  53  54  81  16  59 135  73  85 138  27   2 107  82   5\n",
      "  44 154  80  99 155  26  50 149  17 116  10 105 140  64  39 109 104 144\n",
      "  97  76 101  67   0   8  52 124 115 100 112  30  56  61  78 134 139  75\n",
      " 125  20  60  90 121  46  94 123 153  98  25 127 117  93  96 118  36  14\n",
      "  29 103  24   6 102  35  19  89  38  95  74  37  71 129 150  87 146 132\n",
      "  66 108 131  86   9  91  48  11  13   4  92  88 142  68  62 120 114  83]\n",
      "picked sampling number:  [ 79 147 151  53  54  81  16  59 135  73  85 138  27   2 107  82   5  44\n",
      " 154  80 155  26  50 149  17 116  10 140  64  39 109 104 144  97  76 101\n",
      "  67   8  52 115 100 112  56  61  78 139  75 125  20  60  90 121  46 153\n",
      "  98  25 127  93  29 103  24   6 102  35  19  38  95  74  37 129 150  87\n",
      " 146 132  66  86   9  11   4 142  62 120 114]\n",
      "Constructing No. 7 CRF for COBRE dataset\n",
      "sampling indexes:  [  0  47  17  76  56  30  55 101  67 140 135 116  33  73 144   2 107  39\n",
      "  12 154  81  64 106 134 115  23 155  59  63 147 151 104  61  82  58 109\n",
      "  26   1  75  97  10  28  41 105  79  85   5  99  16  78 149 124 111 139\n",
      " 113 133   6  86  95 102  45 103  15  66  74 121   9  13 110  25  92 153\n",
      " 122 118  88 152   4  98  51 146  48 137 145  69  57  65  35  29   7 108\n",
      "  93 150  24 156  94 143  40  71  11 132 141  84  68  19 125  14  83  34]\n",
      "picked sampling number:  [  0  17  30  55  67 135 116  33  73 144   2  39  12  64 106 134  23 155\n",
      "  63 147 151 104  61  82  26   1  75  10  28  41 105  79  85   5  16  78\n",
      " 149 124 111 139 113 133   6 102  45  15  66 121   9  13 110  25 118  88\n",
      "   4  98  51 146 137 145  65  35   7 108  93 150  24 156  94  40  71 132\n",
      "  84  19 125  14  34]\n",
      "Constructing No. 8 CRF for COBRE dataset\n",
      "sampling indexes:  [111 112  97  63 100  41  81   5  47  10  31  75  55  79  82 147 124   2\n",
      " 151  59  56 144  30  28 106  76 135  99 154  67  44   0 107 116   8  39\n",
      "   1  33  50  73 155  85  78  17 115 139 101  26  72 104  52  77 134 149\n",
      "  91  13 150 137  83 103  60 130  29 114  36 142  49 156  92 117 152  37\n",
      "  57  46 125   7 127  86  20  84  43   6 126 133 123  21  35  95  24  38\n",
      "  45  89 153 119  66  19 146  62 141  14 143  98 132  65  94  68  88 113]\n",
      "picked sampling number:  [111 112  97  63 100  10  31  75  55  79  82 147   2 151  59  56 144  30\n",
      "  28 106  76 135  99 154  67  44   0 107 116   8  39   1  33  73 155  78\n",
      " 139 101  72 104  77 149  91  13 150 103  60 114  36 142  49 156  92 152\n",
      "  46 125 127  86  20  84   6 133 123  21  35  95  24  38  45  89 119  66\n",
      "  19 146  14  98 132  94  88 113]\n",
      "Constructing No. 9 CRF for COBRE dataset\n",
      "sampling indexes:  [149 111  55  50 104  67  85  23  72   0   5  31  78  33 134 138  12  27\n",
      " 135  44 101  79 140  61 105  63 107  30  81  76  73  52 116 124  17 154\n",
      "  75   1   8  47  26 115  99  10  56  97 151  80  58 155  39 112  64 139\n",
      " 123  68   7  15  96 129  95   4 141  60 108  43  93  48 132 128  83  74\n",
      "   6  29 143 146 117  57 142 118  46 121  91 156  22 150  42 130  34  90\n",
      "  11  24  66 145  37  18  40 148 126  86 125 131 120  69  35 152  87 122]\n",
      "picked sampling number:  [149 111  55  50 104  67  85  72   0   5  78  33  27 135  44 101 140  61\n",
      " 105  63 107  30  81  76  73  52 116 124  17   1   8  26  10  56 151  80\n",
      "  58 155  39 112  64 139 123  68   7  15  96 129   4 141  60  93  48  83\n",
      "  74   6 146 117 142 118  46  91 156 150 130  34  11  24  66 145  37  18\n",
      "  40 148 126  86 125 131 120  69  87]\n",
      "Constructing No. 10 CRF for COBRE dataset\n",
      "sampling indexes:  [ 44  76  55  28  31 154 124  79  82 155 134  80  54 101  64  97 138  27\n",
      " 115  67  58  99 100  33  52 140  81 147  73  72   8  53  63   0   5  23\n",
      "  85 111 151 149  47  41  61 135 144  59 106  78   1  39 107   2  26  16\n",
      " 143  43  38 137  42  11  92  36  29  15 152  14   4 110  69  98 113  32\n",
      " 132  88 142  65  86  35  40 136 114  60 121  84 131  70 119  34 141 127\n",
      " 123  49 102  57   3  46 153  94  87  93 148  71  48 145  25   9  19  37]\n",
      "picked sampling number:  [ 44  76  55  28 154  82 155  80  54 101  64  97  67  58  99 100  52  81\n",
      " 147   8  63   0   5  85 151 149  47  41  61 144  59 106  78   1  39 107\n",
      "   2  26 143  38 137  42  11  92  36  29 152   4  69  98 113  32 132  88\n",
      " 142  65  86  40 114  60 121  84 131  70 119  34 141 127  49 102   3  46\n",
      "  94  87  93 148  71 145  25   9  19  37]\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import savemat\n",
    "\n",
    "\n",
    "def perform_crf(\n",
    "    dataset_path: str,\n",
    "    result_path: str,\n",
    "    name: str\n",
    "):\n",
    "    \"\"\"\n",
    "    consisting of subjects with there features as columns\n",
    "    last column is label of the subject\n",
    "    \"\"\"\n",
    "\n",
    "    file_path = os.path.join(dataset_path, f'{name}.mat')\n",
    "    dataset = load_result_matfile(file_path)[name]\n",
    "\n",
    "    subject_count, features_count = dataset.shape\n",
    "\n",
    "    labels = dataset[:, -1]\n",
    "    label_classes = np.unique(labels)\n",
    "    len_label_classes = len(label_classes)\n",
    "    # class is either 1 (SZ) or 2 (HC)\n",
    "    original_cls_label_indexes = dict()\n",
    "    sampling_cls_label_count = [None] * len_label_classes\n",
    "\n",
    "    for i in range(len_label_classes):\n",
    "        original_cls_label_indexes[label_classes[i]] = np.where(\n",
    "            labels == label_classes[i]\n",
    "        )[0]\n",
    "        sampling_cls_label_count[i] = floor(\n",
    "            len(original_cls_label_indexes[label_classes[i]]) * SamplingThs\n",
    "        )\n",
    "\n",
    "    dtype = np.dtype([\n",
    "        (\"subject_id\", np.int64),   # col 0\n",
    "        (\"count\", np.int64),        # col 1\n",
    "        (\"non_noise_count\", np.int64),      # col 2\n",
    "        (\"ratio\", np.float64)       # col 3\n",
    "    ])\n",
    "\n",
    "    sub_noise_per_iter = np.zeros(subject_count, dtype=dtype)\n",
    "    sub_noise_per_iter[\"subject_id\"] = np.arange(1, subject_count + 1, dtype=int) # id's of all subjects\n",
    "    mean_sub_sampling_length = int(np.mean(sampling_cls_label_count))\n",
    "\n",
    "\n",
    "    sampling_indexes = np.zeros(\n",
    "        (len_label_classes * mean_sub_sampling_length, iter), dtype=int\n",
    "    )\n",
    "\n",
    "    non_noise_sampling_subjects = [] # for each sampling, subjects Ids which are not noise\n",
    "    nltc_decisions = []\n",
    "    for i in range(iter):\n",
    "        print(f\"Constructing No. {i+1} CRF for {name} dataset\")\n",
    "        index_temp = []\n",
    "        for cls in label_classes:\n",
    "            random_sampling_indexes = np.random.permutation(\n",
    "                original_cls_label_indexes[cls]\n",
    "            )[:mean_sub_sampling_length]\n",
    "            index_temp.extend(random_sampling_indexes)\n",
    "\n",
    "        sampling_indexes[:, i] = np.array(index_temp).astype(int)\n",
    "\n",
    "        print(\"sampling indexes: \", sampling_indexes[:, i])\n",
    "\n",
    "        sub_noise_per_iter['count'][sampling_indexes[:,i]] += 1\n",
    "        sampled_dataset = dataset[sampling_indexes[:,i], :]\n",
    "        attributes = zscore(sampled_dataset[:, 0:features_count-1], axis=0, ddof=1)\n",
    "        sampled_dataset_labels = sampled_dataset[:, -1].reshape(-1,1)\n",
    "\n",
    "        training_data = np.hstack((sampled_dataset_labels, attributes))\n",
    "\n",
    "        # denoise_data, non_noise_ID, NLTC_labels =  running_crf(training_data, ntree, NI_threshold)\n",
    "        instance = crf.CRF(ntree, NI_threshold)\n",
    "        _, non_noise_ids, nltc_labels = instance.crf_v1(training_data, ntree)\n",
    "        nltc_decisions.append(nltc_labels)\n",
    "        print(\"picked sampling number: \", sampling_indexes[non_noise_ids, i])\n",
    "        non_noise_sampling_subjects.append(sampling_indexes[non_noise_ids, i])\n",
    "\n",
    "    denoise_check = np.zeros((subject_count,), dtype=int)\n",
    "    for i in range(iter):\n",
    "        idxs = non_noise_sampling_subjects[i]\n",
    "        denoise_check [idxs] += 1\n",
    "\n",
    "    # print(\"denoise count for each subject: \", denoise_check)\n",
    "    sub_noise_per_iter['non_noise_count'] = denoise_check\n",
    "\n",
    "    np.divide(sub_noise_per_iter['non_noise_count'], sub_noise_per_iter['count'], out=sub_noise_per_iter['ratio'], where=sub_noise_per_iter['count'] != 0)\n",
    "    sub_noise_per_iter['ratio'] = np.round(sub_noise_per_iter['ratio'], 1)\n",
    "\n",
    "    final_mat = np.column_stack((sub_noise_per_iter[\"subject_id\"], sub_noise_per_iter[\"count\"], sub_noise_per_iter[\"non_noise_count\"], sub_noise_per_iter['ratio']))\n",
    "    # print(\"iteration matrix: \", final_mat)\n",
    "\n",
    "    output_path = os.path.join(result_path, f'{name}_CRF.mat')\n",
    "    savemat(output_path, {\n",
    "        'count': final_mat,\n",
    "        'nltc_labels': nltc_decisions,\n",
    "        'non_noise_ind': non_noise_sampling_subjects\n",
    "    }, do_compression=True)\n",
    "\n",
    "\n",
    "for name in ['FBIRN', 'COBRE']:\n",
    "    perform_crf('dataset', 'results', name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aafce47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1  68  67 1.0]\n",
      "[  2  76  76 1.0]\n",
      "[  3  71  17 0.2]\n",
      "[  4  75  75 1.0]\n",
      "[  5  64   0 0.0]\n",
      "[  6  69  66 1.0]\n",
      "[  7  78  78 1.0]\n",
      "[  8  73  72 1.0]\n",
      "[  9  68  34 0.5]\n",
      "[ 10  69  69 1.0]\n",
      "[ 11  67  67 1.0]\n",
      "[ 12  66  66 1.0]\n",
      "[ 13  71   0 0.0]\n",
      "[ 14  70   0 0.0]\n",
      "[ 15  70  70 1.0]\n",
      "[ 16  69  69 1.0]\n",
      "[ 17  66   0 0.0]\n",
      "[ 18  73   1 0.0]\n",
      "[ 19  72  54 0.8]\n",
      "[ 20  69  69 1.0]\n",
      "[ 21  69  69 1.0]\n",
      "[ 22  70  12 0.2]\n",
      "[ 23  72  72 1.0]\n",
      "[ 24  77  65 0.8]\n",
      "[ 25  75  75 1.0]\n",
      "[ 26  72  72 1.0]\n",
      "[ 27  70  70 1.0]\n",
      "[ 28  73  73 1.0]\n",
      "[ 29  63  63 1.0]\n",
      "[ 30  69   0 0.0]\n",
      "[ 31  61   0 0.0]\n",
      "[ 32  78   0 0.0]\n",
      "[ 33  65   0 0.0]\n",
      "[ 34  72  72 1.0]\n",
      "[ 35  65   0 0.0]\n",
      "[ 36  73   0 0.0]\n",
      "[ 37  66  66 1.0]\n",
      "[ 38  71   0 0.0]\n",
      "[ 39  63  54 0.9]\n",
      "[ 40  73  73 1.0]\n",
      "[ 41  59   3 0.1]\n",
      "[ 42  76  76 1.0]\n",
      "[ 43  66  66 1.0]\n",
      "[ 44  81  81 1.0]\n",
      "[ 45  70  70 1.0]\n",
      "[ 46  67  67 1.0]\n",
      "[ 47  70  70 1.0]\n",
      "[ 48  66  66 1.0]\n",
      "[ 49  75  67 0.9]\n",
      "[ 50  70  70 1.0]\n",
      "[ 51  75   0 0.0]\n",
      "[ 52  72  72 1.0]\n",
      "[ 53  65  61 0.9]\n",
      "[ 54  71   0 0.0]\n",
      "[ 55  65  48 0.7]\n",
      "[ 56  62  56 0.9]\n",
      "[ 57  78  69 0.9]\n",
      "[ 58  71  67 0.9]\n",
      "[ 59  68  68 1.0]\n",
      "[ 60  79  64 0.8]\n",
      "[ 61  60   0 0.0]\n",
      "[ 62  72  61 0.8]\n",
      "[ 63  76  76 1.0]\n",
      "[ 64  77  77 1.0]\n",
      "[ 65  71   1 0.0]\n",
      "[ 66  64  43 0.7]\n",
      "[ 67  65   0 0.0]\n",
      "[ 68  75   0 0.0]\n",
      "[ 69  63  63 1.0]\n",
      "[ 70  69  69 1.0]\n",
      "[ 71  72   0 0.0]\n",
      "[ 72  69  69 1.0]\n",
      "[ 73  78  78 1.0]\n",
      "[ 74  62  62 1.0]\n",
      "[ 75  68  42 0.6]\n",
      "[ 76  65  65 1.0]\n",
      "[ 77  73   4 0.1]\n",
      "[ 78  74  74 1.0]\n",
      "[ 79  71  63 0.9]\n",
      "[ 80  71  71 1.0]\n",
      "[ 81  70  70 1.0]\n",
      "[ 82  59  59 1.0]\n",
      "[ 83  67   0 0.0]\n",
      "[ 84  79   0 0.0]\n",
      "[ 85  67  67 1.0]\n",
      "[ 86  72  72 1.0]\n",
      "[ 87  73  73 1.0]\n",
      "[ 88  65  65 1.0]\n",
      "[ 89  68  15 0.2]\n",
      "[ 90  65   0 0.0]\n",
      "[ 91  64   0 0.0]\n",
      "[ 92  62   1 0.0]\n",
      "[ 93  74  74 1.0]\n",
      "[ 94  72  72 1.0]\n",
      "[ 95  76  76 1.0]\n",
      "[ 96  69  67 1.0]\n",
      "[ 97  67   0 0.0]\n",
      "[ 98  60  60 1.0]\n",
      "[ 99  69  69 1.0]\n",
      "[100  64  64 1.0]\n",
      "[101  78  78 1.0]\n",
      "[102  81  81 1.0]\n",
      "[103  64   4 0.1]\n",
      "[104  68   0 0.0]\n",
      "[105  70  21 0.3]\n",
      "[106  76  76 1.0]\n",
      "[107  55  55 1.0]\n",
      "[108  71  71 1.0]\n",
      "[109  74   0 0.0]\n",
      "[110  68   5 0.1]\n",
      "[111  73  73 1.0]\n",
      "[112  66   0 0.0]\n",
      "[113  67  14 0.2]\n",
      "[114  72  72 1.0]\n",
      "[115  71   0 0.0]\n",
      "[116  68   0 0.0]\n",
      "[117  65   0 0.0]\n",
      "[118  67  51 0.8]\n",
      "[119  63  63 1.0]\n",
      "[120  73  73 1.0]\n",
      "[121  72  72 1.0]\n",
      "[122  76  68 0.9]\n",
      "[123  72  72 1.0]\n",
      "[124  59  59 1.0]\n",
      "[125  69   1 0.0]\n",
      "[126  74  74 1.0]\n",
      "[127  60  45 0.8]\n",
      "[128  68  68 1.0]\n",
      "[129  74  24 0.3]\n",
      "[130  71   0 0.0]\n",
      "[131  80  62 0.8]\n",
      "[132  84  26 0.3]\n",
      "[133  73  73 1.0]\n",
      "[134  74  13 0.2]\n",
      "[135  75   4 0.1]\n",
      "[136  71  71 1.0]\n",
      "[137  72  53 0.7]\n",
      "[138  66   0 0.0]\n",
      "[139  68  68 1.0]\n",
      "[140  67  67 1.0]\n",
      "[141  65  65 1.0]\n",
      "[142  62  62 1.0]\n",
      "[143  63  63 1.0]\n",
      "[144  63   6 0.1]\n",
      "[145  67  67 1.0]\n",
      "[146  56   0 0.0]\n",
      "[147  73   0 0.0]\n",
      "[148  73  73 1.0]\n",
      "[149  70  70 1.0]\n",
      "[150  60   0 0.0]\n",
      "[151  69  69 1.0]\n",
      "[152  71   0 0.0]\n",
      "[153  72   0 0.0]\n",
      "[154  73  73 1.0]\n",
      "[155  74  74 1.0]\n",
      "[156  77   0 0.0]\n",
      "[157  64  64 1.0]\n",
      "[158  69   0 0.0]\n",
      "[159  74   0 0.0]\n",
      "[160  69  69 1.0]\n",
      "[161  71  70 1.0]\n",
      "[162  75  75 1.0]\n",
      "[163  62  62 1.0]\n",
      "[164  69  69 1.0]\n",
      "[165  63  63 1.0]\n",
      "[166  74  37 0.5]\n",
      "[167  81  81 1.0]\n",
      "[168  71  71 1.0]\n",
      "[169  71   0 0.0]\n",
      "[170  72  71 1.0]\n",
      "[171  71  71 1.0]\n",
      "[172  67  67 1.0]\n",
      "[173  63  63 1.0]\n",
      "[174  64   0 0.0]\n",
      "[175  63   0 0.0]\n",
      "[176  69   2 0.0]\n",
      "[177  72   0 0.0]\n",
      "[178  62   0 0.0]\n",
      "[179  81  20 0.2]\n",
      "[180  72  68 0.9]\n",
      "[181  72   0 0.0]\n",
      "[182  73  66 0.9]\n",
      "[183  67   0 0.0]\n",
      "[184  69  69 1.0]\n",
      "[185  71   5 0.1]\n",
      "[186  73  73 1.0]\n",
      "[187  69   0 0.0]\n",
      "[188  72  72 1.0]\n",
      "[189  70  70 1.0]\n",
      "[190  69   0 0.0]\n",
      "[191  72  72 1.0]\n",
      "[192  71  70 1.0]\n",
      "[193  67  40 0.6]\n",
      "[194  80  80 1.0]\n",
      "[195  66  66 1.0]\n",
      "[196  66   0 0.0]\n",
      "[197  67  29 0.4]\n",
      "[198  67  55 0.8]\n",
      "[199  81   0 0.0]\n",
      "[200  76   7 0.1]\n",
      "[201  78   3 0.0]\n",
      "[202  67  66 1.0]\n",
      "[203  76  76 1.0]\n",
      "[204  76  76 1.0]\n",
      "[205  72  72 1.0]\n",
      "[206  73  73 1.0]\n",
      "[207  66  66 1.0]\n",
      "[208  74   0 0.0]\n",
      "[209  70  70 1.0]\n",
      "[210  80  80 1.0]\n",
      "[211  75   0 0.0]\n",
      "[212  69  63 0.9]\n",
      "[213  78  78 1.0]\n",
      "[214  74   0 0.0]\n",
      "[215  64  39 0.6]\n",
      "[216  70   0 0.0]\n",
      "[217  67  67 1.0]\n",
      "[218  79  28 0.4]\n",
      "[219  67  62 0.9]\n",
      "[220  70  70 1.0]\n",
      "[221  74  74 1.0]\n",
      "[222  64  40 0.6]\n",
      "[223  62  61 1.0]\n",
      "[224  65   3 0.0]\n",
      "[225  74  74 1.0]\n",
      "[226  65  65 1.0]\n",
      "[227  78   0 0.0]\n",
      "[228  65   0 0.0]\n",
      "[229  74  74 1.0]\n",
      "[230  64  64 1.0]\n",
      "[231  73  37 0.5]\n",
      "[232  80  77 1.0]\n",
      "[233  61  61 1.0]\n",
      "[234  58  58 1.0]\n",
      "[235  73  73 1.0]\n",
      "[236  70  70 1.0]\n",
      "[237  68  67 1.0]\n",
      "[238  68  68 1.0]\n",
      "[239  67  67 1.0]\n",
      "[240  67  60 0.9]\n",
      "[241  77  77 1.0]\n",
      "[242  76  76 1.0]\n",
      "[243  71  71 1.0]\n",
      "[244  73  73 1.0]\n",
      "[245  68  59 0.9]\n",
      "[246  78  78 1.0]\n",
      "[247  72  72 1.0]\n",
      "[248  75   4 0.1]\n",
      "[249  66  24 0.4]\n",
      "[250  67  67 1.0]\n",
      "[251  65  65 1.0]\n",
      "[252  66  43 0.7]\n",
      "[253  77  77 1.0]\n",
      "[254  75   0 0.0]\n",
      "[255  79  56 0.7]\n",
      "[256  75  75 1.0]\n",
      "[257  70   0 0.0]\n",
      "[258  68  68 1.0]\n",
      "[259  67   0 0.0]\n",
      "[260  77  77 1.0]\n",
      "[261  73  73 1.0]\n",
      "[262  69  69 1.0]\n",
      "[263  71  71 1.0]\n",
      "[264  70  64 0.9]\n",
      "[265  67   3 0.0]\n",
      "[266  66  66 1.0]\n",
      "[267  69   0 0.0]\n",
      "[268  81  81 1.0]\n",
      "[269  66   0 0.0]\n",
      "[270  73   0 0.0]\n",
      "[271  67   6 0.1]\n",
      "[272  74   0 0.0]\n",
      "[273  62  62 1.0]\n",
      "[274  62  62 1.0]\n",
      "[275  66  66 1.0]\n",
      "[276  74  74 1.0]\n",
      "[277  69  69 1.0]\n",
      "[278  75  74 1.0]\n",
      "[279  86   0 0.0]\n",
      "[280  79  79 1.0]\n",
      "[281  62  62 1.0]\n",
      "[282  68  68 1.0]\n",
      "[283  65   0 0.0]\n",
      "[284  69  67 1.0]\n",
      "[285  62  62 1.0]\n",
      "[286  68  68 1.0]\n",
      "[287  69  67 1.0]\n",
      "[288  82  80 1.0]\n",
      "[289  75   0 0.0]\n",
      "[290  78  78 1.0]\n",
      "[291  78  78 1.0]\n",
      "[292  67   0 0.0]\n",
      "[293  62   0 0.0]\n",
      "[294  67  67 1.0]\n",
      "[295  66  66 1.0]\n",
      "[296  72  72 1.0]\n",
      "[297  67  11 0.2]\n",
      "[298  75  75 1.0]\n",
      "[299  72  55 0.8]\n",
      "[300  71  71 1.0]\n",
      "[301  71  23 0.3]\n",
      "[302  73   0 0.0]\n",
      "[303  70  70 1.0]\n",
      "[304  72  72 1.0]\n",
      "[305  71  71 1.0]\n",
      "[306  68  66 1.0]\n",
      "[307  76  26 0.3]\n",
      "[308  77   0 0.0]\n",
      "[309  69   0 0.0]\n",
      "[310  72  72 1.0]\n",
      "[311  72  72 1.0]\n"
     ]
    }
   ],
   "source": [
    "def pretty_print(mat):\n",
    "    \"\"\"Print with ints for first 3 cols, 1 decimal for last.\"\"\"\n",
    "    ids     = mat[:, 0].astype(np.int64)\n",
    "    count   = mat[:, 1].astype(np.int64)\n",
    "    success = mat[:, 2].astype(np.int64)\n",
    "    ratio   = mat[:, 3]\n",
    "    rows = [f\"[{i:>3d} {c:>3d} {s:>3d} {r:>3.1f}]\" for i,c,s,r in zip(ids, count, success, ratio)]\n",
    "    print(\"\\n\".join(rows))\n",
    "\n",
    "crf = load_result_matfile('results/FBIRN_CRF.mat')['count']\n",
    "pretty_print(crf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6975fd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_typical_subjects(input_path: str, data_path: str, name: str, typical_threshold: float) -> None:\n",
    "\n",
    "    input_file = os.path.join(input_path, f'{name}_CRF.mat')\n",
    "    crf_count = load_result_matfile(input_file)['count']\n",
    "    crf_count[:, 3] = np.round(crf_count[:, 3], 1)\n",
    "\n",
    "    data_file = os.path.join(data_path, f'{name}.mat')\n",
    "    data = load_result_matfile(data_file)[name]\n",
    "\n",
    "    original_labels = data[:, -1]\n",
    "    \n",
    "    mask_sz = (crf_count[:,3] >= typical_threshold) & (original_labels == 1)\n",
    "    mask_hc = (crf_count[:,3] >= typical_threshold) & (original_labels == 2)\n",
    "\n",
    "    typical_group_sz = np.where(mask_sz)[0]\n",
    "    typical_group_hc = np.where(mask_hc)[0]\n",
    "\n",
    "    savemat(f'results/{name}_Typ.mat', {\n",
    "        'typical_sz': typical_group_sz,\n",
    "        'typical_hc': typical_group_hc,\n",
    "    }, do_compression=True)\n",
    "\n",
    "for name in [\"FBIRN\", \"COBRE\"]:\n",
    "    find_typical_subjects('results', 'dataset', name, TypThs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007a2287",
   "metadata": {},
   "source": [
    "### Finding Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1919f938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FBIRN :  [1]\n",
      "COBRE :  [0]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# cummulative feature selection using Bonferroni corrected threshold 0.01/(Col-1)\n",
    "def cumulative_features_selection(Pval, PvalPara):\n",
    "    # Pval: 1-D array of p-values\n",
    "    FeaInd = np.argsort(Pval)                  # indices sorted by p-value\n",
    "    SortPval = Pval[FeaInd]                    # sorted p-values\n",
    "\n",
    "    # Find first index where p-value exceeds threshold\n",
    "    above_thresh = np.where(SortPval > PvalPara)[0]\n",
    "    if above_thresh.size > 0:\n",
    "        ind = above_thresh[0]                  # first index above threshold\n",
    "    else:\n",
    "        ind = len(SortPval)                    # all p-values below threshold\n",
    "\n",
    "    Fea = FeaInd[:ind]                         # keep only significant features\n",
    "    return Fea\n",
    "\n",
    "def compute_score(independent_data, typical_data):\n",
    "    col = independent_data.shape[1]\n",
    "    \n",
    "    ind_fea = independent_data[:, :-1]\n",
    "    typical_data_features = typical_data[:, : -1]\n",
    "    \n",
    "    typical_data_labels = typical_data[:, -1]\n",
    "    typical_group_sz = typical_data_features[typical_data_labels == 1, :]\n",
    "    typical_group_hc = typical_data_features[typical_data_labels == 2, :]\n",
    "    \n",
    "    t_stat, p_val = stats.ttest_ind(typical_group_sz, typical_group_hc, axis=0, equal_var=True)\n",
    "    \n",
    "    # print('pvals: ', p_val)\n",
    "    \n",
    "    significant_threshold = 0.01 / (col - 1)\n",
    "    \n",
    "    selected_features = cumulative_features_selection(p_val, significant_threshold)\n",
    "    # print('selected features: ', selected_features)\n",
    "    \n",
    "    center_sz = np.mean(typical_group_sz[:, selected_features], axis=0).reshape(1, -1)\n",
    "    center_hc = np.mean(typical_group_hc[:, selected_features], axis=0).reshape(1, -1)\n",
    "    \n",
    "    \n",
    "    # print(center_sz, center_hc)\n",
    "    \n",
    "    X = ind_fea[:, selected_features]\n",
    "    dist1 = cdist(X, center_sz)\n",
    "    dist2 = cdist(X, center_hc)\n",
    "    \n",
    "    distance_typical_group_sz = dist1.mean(axis=1)\n",
    "    distance_typical_group_hc = dist2.mean(axis=1)\n",
    "    \n",
    "    total_distance = distance_typical_group_sz + distance_typical_group_hc\n",
    "    \n",
    "    A = distance_typical_group_sz / total_distance\n",
    "    B = distance_typical_group_hc / total_distance\n",
    "    \n",
    "    scores = np.tan((A-B)*np.pi / 2)\n",
    "    # print('final_scores: ', scores)\n",
    "    \n",
    "    return scores\n",
    "    \n",
    "\n",
    "def predict_score(subjects: list[str], input_path: str, dataset_path: str, typical_threshold: float):\n",
    "    \n",
    "    total_columns = len(subjects)+1\n",
    "    all_cols = np.arange(total_columns)\n",
    "    \n",
    "    for subject_id in range(len(subjects)):\n",
    "        \n",
    "        sub_name = subjects[subject_id]\n",
    "        \n",
    "        data_file = os.path.join(dataset_path, f'{sub_name}.mat')\n",
    "        independent_data = load_result_matfile(data_file)[sub_name]\n",
    "        subject_count, _ = independent_data.shape\n",
    "        \n",
    "        ind_sub_labels = independent_data[:, -1]\n",
    "        total_columns = len(subjects)+1\n",
    "        independent_score = np.zeros((subject_count, total_columns))\n",
    "        \n",
    "        for main_sub_id in range(len(subjects)):\n",
    "            if main_sub_id == subject_id:\n",
    "                independent_score[:, subject_id] = ind_sub_labels\n",
    "                continue\n",
    "            \n",
    "            main_sub_name = subjects[main_sub_id]\n",
    "            main_sub_path = os.path.join(dataset_path, f'{main_sub_name}.mat')\n",
    "            main_sub_data = load_result_matfile(main_sub_path)[main_sub_name]\n",
    "            \n",
    "            input_crf_path = os.path.join(input_path, f'{main_sub_name}_CRF.mat')\n",
    "            main_sub_crf = load_result_matfile(input_crf_path)['count']\n",
    "            \n",
    "            typical_data = main_sub_data[main_sub_crf[:, 3] >= typical_threshold, :]\n",
    "\n",
    "            independent_score[:, main_sub_id] = compute_score(independent_data, typical_data)\n",
    "        independent_score[:, -1] = independent_score[:, np.setdiff1d(all_cols, [subject_id, total_columns-1])].mean(axis=1)\n",
    "        idx = (independent_score[:, :len(subjects)] == 0).any(axis=1)\n",
    "        independent_score[idx, -1] = 0\n",
    "        \n",
    "        output_path = os.path.join(input_path, f'{sub_name}_Score.mat')\n",
    "        savemat(output_path, {\n",
    "            sub_name: independent_score\n",
    "        }, do_compression = True)\n",
    "    \n",
    "predict_score(['FBIRN', 'COBRE'], 'results/', 'dataset/', TypThs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1431f238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: FBIRN Group: SZ\n",
      "shape: (1, 101) and type: <class 'numpy.ndarray'>\n",
      "Total no.of Typical Subjects:  1\n",
      "[[  0   1   3   5   7  18  20  23  24  27  39  41  43  44  46  48  51  56\n",
      "   59  61  62  63  68  69  72  73  77  78  79  80  86  92  93  94  98  99\n",
      "  101 107 113 119 120 121 125 127 130 132 138 139 142 147 153 154 159 161\n",
      "  166 167 169 170 181 185 188 193 194 197 201 202 203 204 205 209 220 224\n",
      "  228 229 231 233 234 240 241 243 246 250 252 255 259 260 267 272 275 279\n",
      "  281 283 286 289 290 297 298 299 302 303 305]]\n",
      "Dataset: FBIRN Group: HC\n",
      "shape: (1, 95) and type: <class 'numpy.ndarray'>\n",
      "Total no.of Typical Subjects:  1\n",
      "[[  6   9  10  11  14  15  19  22  25  26  28  33  36  38  42  45  47  49\n",
      "   52  55  57  58  71  75  81  84  85  87  95  97 100 105 106 110 117 118\n",
      "  122 123 126 135 140 141 144 148 150 156 160 162 163 164 171 172 179 183\n",
      "  187 190 191 206 208 211 212 216 218 219 222 225 232 235 236 237 238 239\n",
      "  242 244 245 249 257 261 262 263 265 273 274 276 277 280 284 285 287 293\n",
      "  294 295 304 309 310]]\n",
      "\n",
      "\n",
      "\n",
      "Dataset: COBRE Group: SZ\n",
      "shape: (1, 54) and type: <class 'numpy.ndarray'>\n",
      "Total no.of Typical Subjects:  1\n",
      "[[  0   1   2   5   8  10  17  26  27  28  30  33  39  44  52  54  55  56\n",
      "   58  59  61  63  64  67  73  75  76  77  78  80  81  82  85  97  99 100\n",
      "  101 104 106 107 109 111 112 115 116 135 138 139 140 147 149 151 154 155]]\n",
      "Dataset: COBRE Group: HC\n",
      "shape: (1, 52) and type: <class 'numpy.ndarray'>\n",
      "Total no.of Typical Subjects:  1\n",
      "[[  3   4   6   7   9  11  13  14  19  20  21  24  25  34  35  36  38  40\n",
      "   42  45  46  49  51  60  62  66  70  84  87  89  91  93  95  98 102 103\n",
      "  110 113 114 119 120 121 125 127 128 129 132 133 137 146 150 156]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DataName = ['FBIRN', 'COBRE']\n",
    "\n",
    "def handle_typical_groups(name: str, group: str, data: h5py.Dataset):\n",
    "    print(f\"Dataset: {i}\", f\"Group: {group}\")\n",
    "    \n",
    "    # single row, consisting of subject ID's \n",
    "    # representing typical subjects after all the iteration \n",
    "    print(f\"shape: {data.shape} and type: {type(data)}\")\n",
    "    print(\"Total no.of Typical Subjects: \", data.shape[0])\n",
    "    print(data)\n",
    "\n",
    "for i in DataName:\n",
    "    path= f'results/{i}_Typ.mat'\n",
    "    data = load_result_matfile(path)\n",
    "    \n",
    "    handle_typical_groups(i, \"SZ\", data['typical_sz'])\n",
    "    handle_typical_groups(i, \"HC\", data['typical_hc'])\n",
    "    \n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c86761cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Independent Score: FBIRN ========\n",
      "Shape: (311, 3) and type: <class 'numpy.ndarray'>\n",
      "top 5 subjects and there score comparing other dataset\n",
      "[[ 1.         -0.33058244 -0.33058244]\n",
      " [ 1.         -0.47686564 -0.47686564]\n",
      " [ 1.         -0.0847972  -0.0847972 ]\n",
      " [ 1.         -0.36939584 -0.36939584]\n",
      " [ 2.         -0.42497186 -0.42497186]]\n",
      "count of subjects having SZ:  167\n",
      "count of subjects who are healthy:  144\n",
      "======= Independent Score: COBRE ========\n",
      "Shape: (157, 3) and type: <class 'numpy.ndarray'>\n",
      "top 5 subjects and there score comparing other dataset\n",
      "[[-0.21598691  1.         -0.21598691]\n",
      " [-0.45276381  1.         -0.45276381]\n",
      " [-0.23919379  1.         -0.23919379]\n",
      " [ 0.05065942  2.          0.05065942]\n",
      " [ 0.55720257  2.          0.55720257]]\n",
      "count of subjects having SZ:  41\n",
      "count of subjects who are healthy:  116\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def handle_Indep_Score(name: str, data: h5py.Dataset):\n",
    "    print(f\"======= Independent Score: {name} ========\")\n",
    "    \n",
    "    # total subjects of current dataset name, then its classification comparing other dataset \n",
    "    print(f\"Shape: {data.shape} and type: {type(data)}\")\n",
    "    print(\"top 5 subjects and there score comparing other dataset\")\n",
    "    print(data[:5][:])\n",
    "    \n",
    "    total_subjects = data.shape[0]\n",
    "    avg_column = data[:, -1]\n",
    "    sz_subjects_count = np.count_nonzero(avg_column >= 0)\n",
    "    hc_subjects_count = np.count_nonzero(avg_column < 0)\n",
    "    print(\"count of subjects having SZ: \", sz_subjects_count)\n",
    "    print(\"count of subjects who are healthy: \", hc_subjects_count)\n",
    "    \n",
    "\n",
    "DataName = ['FBIRN', 'COBRE']\n",
    "for i in DataName:\n",
    "    path = f'results/{i}_Score.mat'\n",
    "    data = load_result_matfile(path)[i]\n",
    "    handle_Indep_Score(i, data)\n",
    "    # print('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
